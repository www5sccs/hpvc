#ifndef _ROTATINGHEATSOURCE_EXPLICITEULER_RECORDS_STATE_H
#define _ROTATINGHEATSOURCE_EXPLICITEULER_RECORDS_STATE_H

#include "peano/utils/Globals.h"
#include "tarch/compiler/CompilerSpecificSettings.h"
#include "peano/utils/PeanoOptimisations.h"
#ifdef Parallel
	#include "tarch/parallel/Node.h"
#endif
#ifdef Parallel
	#include <mpi.h>
#endif
#include "tarch/logging/Log.h"
#include "tarch/la/Vector.h"
#include <bitset>
#include <complex>
#include <string>
#include <iostream>

namespace rotatingheatsource {
   namespace expliciteuler {
      namespace records {
         class State;
         class StatePacked;
      }
   }
}

#if defined(Parallel)
   /**
    * @author This class is generated by DaStGen
    * 		   DataStructureGenerator (DaStGen)
    * 		   2007-2009 Wolfgang Eckhardt
    * 		   2012      Tobias Weinzierl
    *
    * 		   build date: 20-02-2013 11:21
    *
    * @date   02/04/2013 15:53
    */
   class rotatingheatsource::expliciteuler::records::State { 
      
      public:
         
         typedef rotatingheatsource::expliciteuler::records::StatePacked Packed;
         
         enum LoadBalancingState {
            NoRebalancing = 0, ForkTriggered = 1, Forking = 2, JoinTriggered = 3, Joining = 4, JoinWithMasterTriggered = 5, JoiningWithMaster = 6, HasJoinedWithMaster = 7, IsNewWorkerDueToForkOfExistingDomain = 8
         };
         
         struct PersistentRecords {
            double _updateUMax;
            double _updateUH;
            double _uMax;
            double _uH;
            int _timeStep;
            double _timeStepSize;
            double _time;
            double _numberOfStencilUpdates;
            int _globalPlotCounter;
            #ifdef UseManualAlignment
            tarch::la::Vector<DIMENSIONS,double> _minMeshWidth __attribute__((aligned(VectorisationAlignment)));
            #else
            tarch::la::Vector<DIMENSIONS,double> _minMeshWidth;
            #endif
            #ifdef UseManualAlignment
            tarch::la::Vector<DIMENSIONS,double> _maxMeshWidth __attribute__((aligned(VectorisationAlignment)));
            #else
            tarch::la::Vector<DIMENSIONS,double> _maxMeshWidth;
            #endif
            double _numberOfInnerVertices;
            double _numberOfBoundaryVertices;
            double _numberOfOuterVertices;
            double _numberOfInnerCells;
            double _numberOfOuterCells;
            int _maxLevel;
            bool _hasRefined;
            bool _hasTriggeredRefinementForNextIteration;
            bool _hasErased;
            bool _hasTriggeredEraseForNextIteration;
            bool _hasChangedVertexOrCellState;
            bool _isTraversalInverted;
            LoadBalancingState _loadRebalancingState;
            bool _reduceStateAndCell;
            /**
             * Generated
             */
            PersistentRecords();
            
            /**
             * Generated
             */
            PersistentRecords(const double& updateUMax, const double& updateUH, const double& uMax, const double& uH, const int& timeStep, const double& timeStepSize, const double& time, const double& numberOfStencilUpdates, const int& globalPlotCounter, const tarch::la::Vector<DIMENSIONS,double>& minMeshWidth, const tarch::la::Vector<DIMENSIONS,double>& maxMeshWidth, const double& numberOfInnerVertices, const double& numberOfBoundaryVertices, const double& numberOfOuterVertices, const double& numberOfInnerCells, const double& numberOfOuterCells, const int& maxLevel, const bool& hasRefined, const bool& hasTriggeredRefinementForNextIteration, const bool& hasErased, const bool& hasTriggeredEraseForNextIteration, const bool& hasChangedVertexOrCellState, const bool& isTraversalInverted, const LoadBalancingState& loadRebalancingState, const bool& reduceStateAndCell);
            
            
            inline double getUpdateUMax() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _updateUMax;
            }
            
            
            
            inline void setUpdateUMax(const double& updateUMax) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _updateUMax = updateUMax;
            }
            
            
            
            inline double getUpdateUH() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _updateUH;
            }
            
            
            
            inline void setUpdateUH(const double& updateUH) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _updateUH = updateUH;
            }
            
            
            
            inline double getUMax() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _uMax;
            }
            
            
            
            inline void setUMax(const double& uMax) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _uMax = uMax;
            }
            
            
            
            inline double getUH() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _uH;
            }
            
            
            
            inline void setUH(const double& uH) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _uH = uH;
            }
            
            
            
            inline int getTimeStep() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _timeStep;
            }
            
            
            
            inline void setTimeStep(const int& timeStep) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _timeStep = timeStep;
            }
            
            
            
            inline double getTimeStepSize() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _timeStepSize;
            }
            
            
            
            inline void setTimeStepSize(const double& timeStepSize) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _timeStepSize = timeStepSize;
            }
            
            
            
            inline double getTime() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _time;
            }
            
            
            
            inline void setTime(const double& time) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _time = time;
            }
            
            
            
            inline double getNumberOfStencilUpdates() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _numberOfStencilUpdates;
            }
            
            
            
            inline void setNumberOfStencilUpdates(const double& numberOfStencilUpdates) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _numberOfStencilUpdates = numberOfStencilUpdates;
            }
            
            
            
            inline int getGlobalPlotCounter() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _globalPlotCounter;
            }
            
            
            
            inline void setGlobalPlotCounter(const int& globalPlotCounter) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _globalPlotCounter = globalPlotCounter;
            }
            
            
            
            /**
             * Generated and optimized
             * 
             * If you realise a for loop using exclusively arrays (vectors) and compile 
             * with -DUseManualAlignment you may add 
             * \code
             #pragma vector aligned
             #pragma simd
             \endcode to this for loop to enforce your compiler to use SSE/AVX.
             * 
             * The alignment is tied to the unpacked records, i.e. for packed class
             * variants the machine's natural alignment is switched off to recude the  
             * memory footprint. Do not use any SSE/AVX operations or 
             * vectorisation on the result for the packed variants, as the data is misaligned. 
             * If you rely on vectorisation, convert the underlying record 
             * into the unpacked version first. 
             * 
             * @see convert()
             */
            inline tarch::la::Vector<DIMENSIONS,double> getMinMeshWidth() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _minMeshWidth;
            }
            
            
            
            /**
             * Generated and optimized
             * 
             * If you realise a for loop using exclusively arrays (vectors) and compile 
             * with -DUseManualAlignment you may add 
             * \code
             #pragma vector aligned
             #pragma simd
             \endcode to this for loop to enforce your compiler to use SSE/AVX.
             * 
             * The alignment is tied to the unpacked records, i.e. for packed class
             * variants the machine's natural alignment is switched off to recude the  
             * memory footprint. Do not use any SSE/AVX operations or 
             * vectorisation on the result for the packed variants, as the data is misaligned. 
             * If you rely on vectorisation, convert the underlying record 
             * into the unpacked version first. 
             * 
             * @see convert()
             */
            inline void setMinMeshWidth(const tarch::la::Vector<DIMENSIONS,double>& minMeshWidth) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _minMeshWidth = (minMeshWidth);
            }
            
            
            
            /**
             * Generated and optimized
             * 
             * If you realise a for loop using exclusively arrays (vectors) and compile 
             * with -DUseManualAlignment you may add 
             * \code
             #pragma vector aligned
             #pragma simd
             \endcode to this for loop to enforce your compiler to use SSE/AVX.
             * 
             * The alignment is tied to the unpacked records, i.e. for packed class
             * variants the machine's natural alignment is switched off to recude the  
             * memory footprint. Do not use any SSE/AVX operations or 
             * vectorisation on the result for the packed variants, as the data is misaligned. 
             * If you rely on vectorisation, convert the underlying record 
             * into the unpacked version first. 
             * 
             * @see convert()
             */
            inline tarch::la::Vector<DIMENSIONS,double> getMaxMeshWidth() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _maxMeshWidth;
            }
            
            
            
            /**
             * Generated and optimized
             * 
             * If you realise a for loop using exclusively arrays (vectors) and compile 
             * with -DUseManualAlignment you may add 
             * \code
             #pragma vector aligned
             #pragma simd
             \endcode to this for loop to enforce your compiler to use SSE/AVX.
             * 
             * The alignment is tied to the unpacked records, i.e. for packed class
             * variants the machine's natural alignment is switched off to recude the  
             * memory footprint. Do not use any SSE/AVX operations or 
             * vectorisation on the result for the packed variants, as the data is misaligned. 
             * If you rely on vectorisation, convert the underlying record 
             * into the unpacked version first. 
             * 
             * @see convert()
             */
            inline void setMaxMeshWidth(const tarch::la::Vector<DIMENSIONS,double>& maxMeshWidth) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _maxMeshWidth = (maxMeshWidth);
            }
            
            
            
            inline double getNumberOfInnerVertices() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _numberOfInnerVertices;
            }
            
            
            
            inline void setNumberOfInnerVertices(const double& numberOfInnerVertices) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _numberOfInnerVertices = numberOfInnerVertices;
            }
            
            
            
            inline double getNumberOfBoundaryVertices() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _numberOfBoundaryVertices;
            }
            
            
            
            inline void setNumberOfBoundaryVertices(const double& numberOfBoundaryVertices) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _numberOfBoundaryVertices = numberOfBoundaryVertices;
            }
            
            
            
            inline double getNumberOfOuterVertices() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _numberOfOuterVertices;
            }
            
            
            
            inline void setNumberOfOuterVertices(const double& numberOfOuterVertices) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _numberOfOuterVertices = numberOfOuterVertices;
            }
            
            
            
            inline double getNumberOfInnerCells() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _numberOfInnerCells;
            }
            
            
            
            inline void setNumberOfInnerCells(const double& numberOfInnerCells) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _numberOfInnerCells = numberOfInnerCells;
            }
            
            
            
            inline double getNumberOfOuterCells() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _numberOfOuterCells;
            }
            
            
            
            inline void setNumberOfOuterCells(const double& numberOfOuterCells) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _numberOfOuterCells = numberOfOuterCells;
            }
            
            
            
            inline int getMaxLevel() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _maxLevel;
            }
            
            
            
            inline void setMaxLevel(const int& maxLevel) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _maxLevel = maxLevel;
            }
            
            
            
            inline bool getHasRefined() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _hasRefined;
            }
            
            
            
            inline void setHasRefined(const bool& hasRefined) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _hasRefined = hasRefined;
            }
            
            
            
            inline bool getHasTriggeredRefinementForNextIteration() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _hasTriggeredRefinementForNextIteration;
            }
            
            
            
            inline void setHasTriggeredRefinementForNextIteration(const bool& hasTriggeredRefinementForNextIteration) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _hasTriggeredRefinementForNextIteration = hasTriggeredRefinementForNextIteration;
            }
            
            
            
            inline bool getHasErased() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _hasErased;
            }
            
            
            
            inline void setHasErased(const bool& hasErased) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _hasErased = hasErased;
            }
            
            
            
            inline bool getHasTriggeredEraseForNextIteration() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _hasTriggeredEraseForNextIteration;
            }
            
            
            
            inline void setHasTriggeredEraseForNextIteration(const bool& hasTriggeredEraseForNextIteration) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _hasTriggeredEraseForNextIteration = hasTriggeredEraseForNextIteration;
            }
            
            
            
            inline bool getHasChangedVertexOrCellState() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _hasChangedVertexOrCellState;
            }
            
            
            
            inline void setHasChangedVertexOrCellState(const bool& hasChangedVertexOrCellState) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _hasChangedVertexOrCellState = hasChangedVertexOrCellState;
            }
            
            
            
            inline bool getIsTraversalInverted() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _isTraversalInverted;
            }
            
            
            
            inline void setIsTraversalInverted(const bool& isTraversalInverted) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _isTraversalInverted = isTraversalInverted;
            }
            
            
            
            inline LoadBalancingState getLoadRebalancingState() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _loadRebalancingState;
            }
            
            
            
            inline void setLoadRebalancingState(const LoadBalancingState& loadRebalancingState) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _loadRebalancingState = loadRebalancingState;
            }
            
            
            
            inline bool getReduceStateAndCell() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _reduceStateAndCell;
            }
            
            
            
            inline void setReduceStateAndCell(const bool& reduceStateAndCell) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _reduceStateAndCell = reduceStateAndCell;
            }
            
            
            
         };
         
      private: 
         PersistentRecords _persistentRecords;
         
      public:
         /**
          * Generated
          */
         State();
         
         /**
          * Generated
          */
         State(const PersistentRecords& persistentRecords);
         
         /**
          * Generated
          */
         State(const double& updateUMax, const double& updateUH, const double& uMax, const double& uH, const int& timeStep, const double& timeStepSize, const double& time, const double& numberOfStencilUpdates, const int& globalPlotCounter, const tarch::la::Vector<DIMENSIONS,double>& minMeshWidth, const tarch::la::Vector<DIMENSIONS,double>& maxMeshWidth, const double& numberOfInnerVertices, const double& numberOfBoundaryVertices, const double& numberOfOuterVertices, const double& numberOfInnerCells, const double& numberOfOuterCells, const int& maxLevel, const bool& hasRefined, const bool& hasTriggeredRefinementForNextIteration, const bool& hasErased, const bool& hasTriggeredEraseForNextIteration, const bool& hasChangedVertexOrCellState, const bool& isTraversalInverted, const LoadBalancingState& loadRebalancingState, const bool& reduceStateAndCell);
         
         /**
          * Generated
          */
         virtual ~State();
         
         
         inline double getUpdateUMax() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            return _persistentRecords._updateUMax;
         }
         
         
         
         inline void setUpdateUMax(const double& updateUMax) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            _persistentRecords._updateUMax = updateUMax;
         }
         
         
         
         inline double getUpdateUH() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            return _persistentRecords._updateUH;
         }
         
         
         
         inline void setUpdateUH(const double& updateUH) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            _persistentRecords._updateUH = updateUH;
         }
         
         
         
         inline double getUMax() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            return _persistentRecords._uMax;
         }
         
         
         
         inline void setUMax(const double& uMax) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            _persistentRecords._uMax = uMax;
         }
         
         
         
         inline double getUH() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            return _persistentRecords._uH;
         }
         
         
         
         inline void setUH(const double& uH) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            _persistentRecords._uH = uH;
         }
         
         
         
         inline int getTimeStep() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            return _persistentRecords._timeStep;
         }
         
         
         
         inline void setTimeStep(const int& timeStep) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            _persistentRecords._timeStep = timeStep;
         }
         
         
         
         inline double getTimeStepSize() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            return _persistentRecords._timeStepSize;
         }
         
         
         
         inline void setTimeStepSize(const double& timeStepSize) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            _persistentRecords._timeStepSize = timeStepSize;
         }
         
         
         
         inline double getTime() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            return _persistentRecords._time;
         }
         
         
         
         inline void setTime(const double& time) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            _persistentRecords._time = time;
         }
         
         
         
         inline double getNumberOfStencilUpdates() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            return _persistentRecords._numberOfStencilUpdates;
         }
         
         
         
         inline void setNumberOfStencilUpdates(const double& numberOfStencilUpdates) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            _persistentRecords._numberOfStencilUpdates = numberOfStencilUpdates;
         }
         
         
         
         inline int getGlobalPlotCounter() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            return _persistentRecords._globalPlotCounter;
         }
         
         
         
         inline void setGlobalPlotCounter(const int& globalPlotCounter) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            _persistentRecords._globalPlotCounter = globalPlotCounter;
         }
         
         
         
         /**
          * Generated and optimized
          * 
          * If you realise a for loop using exclusively arrays (vectors) and compile 
          * with -DUseManualAlignment you may add 
          * \code
          #pragma vector aligned
          #pragma simd
          \endcode to this for loop to enforce your compiler to use SSE/AVX.
          * 
          * The alignment is tied to the unpacked records, i.e. for packed class
          * variants the machine's natural alignment is switched off to recude the  
          * memory footprint. Do not use any SSE/AVX operations or 
          * vectorisation on the result for the packed variants, as the data is misaligned. 
          * If you rely on vectorisation, convert the underlying record 
          * into the unpacked version first. 
          * 
          * @see convert()
          */
         inline tarch::la::Vector<DIMENSIONS,double> getMinMeshWidth() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            return _persistentRecords._minMeshWidth;
         }
         
         
         
         /**
          * Generated and optimized
          * 
          * If you realise a for loop using exclusively arrays (vectors) and compile 
          * with -DUseManualAlignment you may add 
          * \code
          #pragma vector aligned
          #pragma simd
          \endcode to this for loop to enforce your compiler to use SSE/AVX.
          * 
          * The alignment is tied to the unpacked records, i.e. for packed class
          * variants the machine's natural alignment is switched off to recude the  
          * memory footprint. Do not use any SSE/AVX operations or 
          * vectorisation on the result for the packed variants, as the data is misaligned. 
          * If you rely on vectorisation, convert the underlying record 
          * into the unpacked version first. 
          * 
          * @see convert()
          */
         inline void setMinMeshWidth(const tarch::la::Vector<DIMENSIONS,double>& minMeshWidth) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            _persistentRecords._minMeshWidth = (minMeshWidth);
         }
         
         
         
         inline double getMinMeshWidth(int elementIndex) const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            assertion(elementIndex>=0);
            assertion(elementIndex<DIMENSIONS);
            return _persistentRecords._minMeshWidth[elementIndex];
            
         }
         
         
         
         inline void setMinMeshWidth(int elementIndex, const double& minMeshWidth) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            assertion(elementIndex>=0);
            assertion(elementIndex<DIMENSIONS);
            _persistentRecords._minMeshWidth[elementIndex]= minMeshWidth;
            
         }
         
         
         
         /**
          * Generated and optimized
          * 
          * If you realise a for loop using exclusively arrays (vectors) and compile 
          * with -DUseManualAlignment you may add 
          * \code
          #pragma vector aligned
          #pragma simd
          \endcode to this for loop to enforce your compiler to use SSE/AVX.
          * 
          * The alignment is tied to the unpacked records, i.e. for packed class
          * variants the machine's natural alignment is switched off to recude the  
          * memory footprint. Do not use any SSE/AVX operations or 
          * vectorisation on the result for the packed variants, as the data is misaligned. 
          * If you rely on vectorisation, convert the underlying record 
          * into the unpacked version first. 
          * 
          * @see convert()
          */
         inline tarch::la::Vector<DIMENSIONS,double> getMaxMeshWidth() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            return _persistentRecords._maxMeshWidth;
         }
         
         
         
         /**
          * Generated and optimized
          * 
          * If you realise a for loop using exclusively arrays (vectors) and compile 
          * with -DUseManualAlignment you may add 
          * \code
          #pragma vector aligned
          #pragma simd
          \endcode to this for loop to enforce your compiler to use SSE/AVX.
          * 
          * The alignment is tied to the unpacked records, i.e. for packed class
          * variants the machine's natural alignment is switched off to recude the  
          * memory footprint. Do not use any SSE/AVX operations or 
          * vectorisation on the result for the packed variants, as the data is misaligned. 
          * If you rely on vectorisation, convert the underlying record 
          * into the unpacked version first. 
          * 
          * @see convert()
          */
         inline void setMaxMeshWidth(const tarch::la::Vector<DIMENSIONS,double>& maxMeshWidth) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            _persistentRecords._maxMeshWidth = (maxMeshWidth);
         }
         
         
         
         inline double getMaxMeshWidth(int elementIndex) const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            assertion(elementIndex>=0);
            assertion(elementIndex<DIMENSIONS);
            return _persistentRecords._maxMeshWidth[elementIndex];
            
         }
         
         
         
         inline void setMaxMeshWidth(int elementIndex, const double& maxMeshWidth) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            assertion(elementIndex>=0);
            assertion(elementIndex<DIMENSIONS);
            _persistentRecords._maxMeshWidth[elementIndex]= maxMeshWidth;
            
         }
         
         
         
         inline double getNumberOfInnerVertices() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            return _persistentRecords._numberOfInnerVertices;
         }
         
         
         
         inline void setNumberOfInnerVertices(const double& numberOfInnerVertices) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            _persistentRecords._numberOfInnerVertices = numberOfInnerVertices;
         }
         
         
         
         inline double getNumberOfBoundaryVertices() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            return _persistentRecords._numberOfBoundaryVertices;
         }
         
         
         
         inline void setNumberOfBoundaryVertices(const double& numberOfBoundaryVertices) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            _persistentRecords._numberOfBoundaryVertices = numberOfBoundaryVertices;
         }
         
         
         
         inline double getNumberOfOuterVertices() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            return _persistentRecords._numberOfOuterVertices;
         }
         
         
         
         inline void setNumberOfOuterVertices(const double& numberOfOuterVertices) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            _persistentRecords._numberOfOuterVertices = numberOfOuterVertices;
         }
         
         
         
         inline double getNumberOfInnerCells() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            return _persistentRecords._numberOfInnerCells;
         }
         
         
         
         inline void setNumberOfInnerCells(const double& numberOfInnerCells) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            _persistentRecords._numberOfInnerCells = numberOfInnerCells;
         }
         
         
         
         inline double getNumberOfOuterCells() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            return _persistentRecords._numberOfOuterCells;
         }
         
         
         
         inline void setNumberOfOuterCells(const double& numberOfOuterCells) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            _persistentRecords._numberOfOuterCells = numberOfOuterCells;
         }
         
         
         
         inline int getMaxLevel() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            return _persistentRecords._maxLevel;
         }
         
         
         
         inline void setMaxLevel(const int& maxLevel) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            _persistentRecords._maxLevel = maxLevel;
         }
         
         
         
         inline bool getHasRefined() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            return _persistentRecords._hasRefined;
         }
         
         
         
         inline void setHasRefined(const bool& hasRefined) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            _persistentRecords._hasRefined = hasRefined;
         }
         
         
         
         inline bool getHasTriggeredRefinementForNextIteration() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            return _persistentRecords._hasTriggeredRefinementForNextIteration;
         }
         
         
         
         inline void setHasTriggeredRefinementForNextIteration(const bool& hasTriggeredRefinementForNextIteration) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            _persistentRecords._hasTriggeredRefinementForNextIteration = hasTriggeredRefinementForNextIteration;
         }
         
         
         
         inline bool getHasErased() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            return _persistentRecords._hasErased;
         }
         
         
         
         inline void setHasErased(const bool& hasErased) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            _persistentRecords._hasErased = hasErased;
         }
         
         
         
         inline bool getHasTriggeredEraseForNextIteration() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            return _persistentRecords._hasTriggeredEraseForNextIteration;
         }
         
         
         
         inline void setHasTriggeredEraseForNextIteration(const bool& hasTriggeredEraseForNextIteration) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            _persistentRecords._hasTriggeredEraseForNextIteration = hasTriggeredEraseForNextIteration;
         }
         
         
         
         inline bool getHasChangedVertexOrCellState() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            return _persistentRecords._hasChangedVertexOrCellState;
         }
         
         
         
         inline void setHasChangedVertexOrCellState(const bool& hasChangedVertexOrCellState) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            _persistentRecords._hasChangedVertexOrCellState = hasChangedVertexOrCellState;
         }
         
         
         
         inline bool getIsTraversalInverted() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            return _persistentRecords._isTraversalInverted;
         }
         
         
         
         inline void setIsTraversalInverted(const bool& isTraversalInverted) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            _persistentRecords._isTraversalInverted = isTraversalInverted;
         }
         
         
         
         inline LoadBalancingState getLoadRebalancingState() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            return _persistentRecords._loadRebalancingState;
         }
         
         
         
         inline void setLoadRebalancingState(const LoadBalancingState& loadRebalancingState) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            _persistentRecords._loadRebalancingState = loadRebalancingState;
         }
         
         
         
         inline bool getReduceStateAndCell() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            return _persistentRecords._reduceStateAndCell;
         }
         
         
         
         inline void setReduceStateAndCell(const bool& reduceStateAndCell) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
            _persistentRecords._reduceStateAndCell = reduceStateAndCell;
         }
         
         
         /**
          * Generated
          */
         static std::string toString(const LoadBalancingState& param);
         
         /**
          * Generated
          */
         static std::string getLoadBalancingStateMapping();
         
         /**
          * Generated
          */
         std::string toString() const;
         
         /**
          * Generated
          */
         void toString(std::ostream& out) const;
         
         
         PersistentRecords getPersistentRecords() const;
         /**
          * Generated
          */
         StatePacked convert() const;
         
         
      #ifdef Parallel
         protected:
            static tarch::logging::Log _log;
            
            int _senderDestinationRank;
            
         public:
            
            /**
             * Global that represents the mpi datatype.
             * There are two variants: Datatype identifies only those attributes marked with
             * parallelise. FullDatatype instead identifies the whole record with all fields.
             */
            static MPI_Datatype Datatype;
            static MPI_Datatype FullDatatype;
            
            /**
             * Initializes the data type for the mpi operations. Has to be called
             * before the very first send or receive operation is called.
             */
            static void initDatatype();
            
            static void shutdownDatatype();
            
            void send(int destination, int tag, bool exchangeOnlyAttributesMarkedWithParallelise);
            
            void receive(int source, int tag, bool exchangeOnlyAttributesMarkedWithParallelise);
            
            static bool isMessageInQueue(int tag, bool exchangeOnlyAttributesMarkedWithParallelise);
            
            int getSenderRank() const;
            
      #endif
         
      };
      
      #ifndef DaStGenPackedPadding
        #define DaStGenPackedPadding 1      // 32 bit version
        // #define DaStGenPackedPadding 2   // 64 bit version
      #endif
      
      
      #ifdef PackedRecords
         #pragma pack (push, DaStGenPackedPadding)
      #endif
      
      /**
       * @author This class is generated by DaStGen
       * 		   DataStructureGenerator (DaStGen)
       * 		   2007-2009 Wolfgang Eckhardt
       * 		   2012      Tobias Weinzierl
       *
       * 		   build date: 20-02-2013 11:21
       *
       * @date   02/04/2013 15:53
       */
      class rotatingheatsource::expliciteuler::records::StatePacked { 
         
         public:
            
            typedef rotatingheatsource::expliciteuler::records::State::LoadBalancingState LoadBalancingState;
            
            struct PersistentRecords {
               double _updateUMax;
               double _updateUH;
               double _uMax;
               double _uH;
               int _timeStep;
               double _timeStepSize;
               double _time;
               double _numberOfStencilUpdates;
               int _globalPlotCounter;
               tarch::la::Vector<DIMENSIONS,double> _minMeshWidth;
               tarch::la::Vector<DIMENSIONS,double> _maxMeshWidth;
               double _numberOfInnerVertices;
               double _numberOfBoundaryVertices;
               double _numberOfOuterVertices;
               double _numberOfInnerCells;
               double _numberOfOuterCells;
               int _maxLevel;
               bool _isTraversalInverted;
               LoadBalancingState _loadRebalancingState;
               
               /** mapping of records:
               || Member 	|| startbit 	|| length
                |  hasRefined	| startbit 0	| #bits 1
                |  hasTriggeredRefinementForNextIteration	| startbit 1	| #bits 1
                |  hasErased	| startbit 2	| #bits 1
                |  hasTriggeredEraseForNextIteration	| startbit 3	| #bits 1
                |  hasChangedVertexOrCellState	| startbit 4	| #bits 1
                |  reduceStateAndCell	| startbit 5	| #bits 1
                */
               short int _packedRecords0;
               
               /**
                * Generated
                */
               PersistentRecords();
               
               /**
                * Generated
                */
               PersistentRecords(const double& updateUMax, const double& updateUH, const double& uMax, const double& uH, const int& timeStep, const double& timeStepSize, const double& time, const double& numberOfStencilUpdates, const int& globalPlotCounter, const tarch::la::Vector<DIMENSIONS,double>& minMeshWidth, const tarch::la::Vector<DIMENSIONS,double>& maxMeshWidth, const double& numberOfInnerVertices, const double& numberOfBoundaryVertices, const double& numberOfOuterVertices, const double& numberOfInnerCells, const double& numberOfOuterCells, const int& maxLevel, const bool& hasRefined, const bool& hasTriggeredRefinementForNextIteration, const bool& hasErased, const bool& hasTriggeredEraseForNextIteration, const bool& hasChangedVertexOrCellState, const bool& isTraversalInverted, const LoadBalancingState& loadRebalancingState, const bool& reduceStateAndCell);
               
               
               inline double getUpdateUMax() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _updateUMax;
               }
               
               
               
               inline void setUpdateUMax(const double& updateUMax) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _updateUMax = updateUMax;
               }
               
               
               
               inline double getUpdateUH() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _updateUH;
               }
               
               
               
               inline void setUpdateUH(const double& updateUH) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _updateUH = updateUH;
               }
               
               
               
               inline double getUMax() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _uMax;
               }
               
               
               
               inline void setUMax(const double& uMax) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _uMax = uMax;
               }
               
               
               
               inline double getUH() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _uH;
               }
               
               
               
               inline void setUH(const double& uH) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _uH = uH;
               }
               
               
               
               inline int getTimeStep() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _timeStep;
               }
               
               
               
               inline void setTimeStep(const int& timeStep) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _timeStep = timeStep;
               }
               
               
               
               inline double getTimeStepSize() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _timeStepSize;
               }
               
               
               
               inline void setTimeStepSize(const double& timeStepSize) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _timeStepSize = timeStepSize;
               }
               
               
               
               inline double getTime() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _time;
               }
               
               
               
               inline void setTime(const double& time) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _time = time;
               }
               
               
               
               inline double getNumberOfStencilUpdates() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _numberOfStencilUpdates;
               }
               
               
               
               inline void setNumberOfStencilUpdates(const double& numberOfStencilUpdates) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _numberOfStencilUpdates = numberOfStencilUpdates;
               }
               
               
               
               inline int getGlobalPlotCounter() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _globalPlotCounter;
               }
               
               
               
               inline void setGlobalPlotCounter(const int& globalPlotCounter) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _globalPlotCounter = globalPlotCounter;
               }
               
               
               
               /**
                * Generated and optimized
                * 
                * If you realise a for loop using exclusively arrays (vectors) and compile 
                * with -DUseManualAlignment you may add 
                * \code
                #pragma vector aligned
                #pragma simd
                \endcode to this for loop to enforce your compiler to use SSE/AVX.
                * 
                * The alignment is tied to the unpacked records, i.e. for packed class
                * variants the machine's natural alignment is switched off to recude the  
                * memory footprint. Do not use any SSE/AVX operations or 
                * vectorisation on the result for the packed variants, as the data is misaligned. 
                * If you rely on vectorisation, convert the underlying record 
                * into the unpacked version first. 
                * 
                * @see convert()
                */
               inline tarch::la::Vector<DIMENSIONS,double> getMinMeshWidth() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _minMeshWidth;
               }
               
               
               
               /**
                * Generated and optimized
                * 
                * If you realise a for loop using exclusively arrays (vectors) and compile 
                * with -DUseManualAlignment you may add 
                * \code
                #pragma vector aligned
                #pragma simd
                \endcode to this for loop to enforce your compiler to use SSE/AVX.
                * 
                * The alignment is tied to the unpacked records, i.e. for packed class
                * variants the machine's natural alignment is switched off to recude the  
                * memory footprint. Do not use any SSE/AVX operations or 
                * vectorisation on the result for the packed variants, as the data is misaligned. 
                * If you rely on vectorisation, convert the underlying record 
                * into the unpacked version first. 
                * 
                * @see convert()
                */
               inline void setMinMeshWidth(const tarch::la::Vector<DIMENSIONS,double>& minMeshWidth) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _minMeshWidth = (minMeshWidth);
               }
               
               
               
               /**
                * Generated and optimized
                * 
                * If you realise a for loop using exclusively arrays (vectors) and compile 
                * with -DUseManualAlignment you may add 
                * \code
                #pragma vector aligned
                #pragma simd
                \endcode to this for loop to enforce your compiler to use SSE/AVX.
                * 
                * The alignment is tied to the unpacked records, i.e. for packed class
                * variants the machine's natural alignment is switched off to recude the  
                * memory footprint. Do not use any SSE/AVX operations or 
                * vectorisation on the result for the packed variants, as the data is misaligned. 
                * If you rely on vectorisation, convert the underlying record 
                * into the unpacked version first. 
                * 
                * @see convert()
                */
               inline tarch::la::Vector<DIMENSIONS,double> getMaxMeshWidth() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _maxMeshWidth;
               }
               
               
               
               /**
                * Generated and optimized
                * 
                * If you realise a for loop using exclusively arrays (vectors) and compile 
                * with -DUseManualAlignment you may add 
                * \code
                #pragma vector aligned
                #pragma simd
                \endcode to this for loop to enforce your compiler to use SSE/AVX.
                * 
                * The alignment is tied to the unpacked records, i.e. for packed class
                * variants the machine's natural alignment is switched off to recude the  
                * memory footprint. Do not use any SSE/AVX operations or 
                * vectorisation on the result for the packed variants, as the data is misaligned. 
                * If you rely on vectorisation, convert the underlying record 
                * into the unpacked version first. 
                * 
                * @see convert()
                */
               inline void setMaxMeshWidth(const tarch::la::Vector<DIMENSIONS,double>& maxMeshWidth) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _maxMeshWidth = (maxMeshWidth);
               }
               
               
               
               inline double getNumberOfInnerVertices() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _numberOfInnerVertices;
               }
               
               
               
               inline void setNumberOfInnerVertices(const double& numberOfInnerVertices) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _numberOfInnerVertices = numberOfInnerVertices;
               }
               
               
               
               inline double getNumberOfBoundaryVertices() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _numberOfBoundaryVertices;
               }
               
               
               
               inline void setNumberOfBoundaryVertices(const double& numberOfBoundaryVertices) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _numberOfBoundaryVertices = numberOfBoundaryVertices;
               }
               
               
               
               inline double getNumberOfOuterVertices() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _numberOfOuterVertices;
               }
               
               
               
               inline void setNumberOfOuterVertices(const double& numberOfOuterVertices) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _numberOfOuterVertices = numberOfOuterVertices;
               }
               
               
               
               inline double getNumberOfInnerCells() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _numberOfInnerCells;
               }
               
               
               
               inline void setNumberOfInnerCells(const double& numberOfInnerCells) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _numberOfInnerCells = numberOfInnerCells;
               }
               
               
               
               inline double getNumberOfOuterCells() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _numberOfOuterCells;
               }
               
               
               
               inline void setNumberOfOuterCells(const double& numberOfOuterCells) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _numberOfOuterCells = numberOfOuterCells;
               }
               
               
               
               inline int getMaxLevel() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _maxLevel;
               }
               
               
               
               inline void setMaxLevel(const int& maxLevel) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _maxLevel = maxLevel;
               }
               
               
               
               inline bool getHasRefined() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  short int mask = 1 << (0);
   short int tmp = static_cast<short int>(_packedRecords0 & mask);
   return (tmp != 0);
               }
               
               
               
               inline void setHasRefined(const bool& hasRefined) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  short int mask = 1 << (0);
   _packedRecords0 = static_cast<short int>( hasRefined ? (_packedRecords0 | mask) : (_packedRecords0 & ~mask));
               }
               
               
               
               inline bool getHasTriggeredRefinementForNextIteration() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  short int mask = 1 << (1);
   short int tmp = static_cast<short int>(_packedRecords0 & mask);
   return (tmp != 0);
               }
               
               
               
               inline void setHasTriggeredRefinementForNextIteration(const bool& hasTriggeredRefinementForNextIteration) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  short int mask = 1 << (1);
   _packedRecords0 = static_cast<short int>( hasTriggeredRefinementForNextIteration ? (_packedRecords0 | mask) : (_packedRecords0 & ~mask));
               }
               
               
               
               inline bool getHasErased() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  short int mask = 1 << (2);
   short int tmp = static_cast<short int>(_packedRecords0 & mask);
   return (tmp != 0);
               }
               
               
               
               inline void setHasErased(const bool& hasErased) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  short int mask = 1 << (2);
   _packedRecords0 = static_cast<short int>( hasErased ? (_packedRecords0 | mask) : (_packedRecords0 & ~mask));
               }
               
               
               
               inline bool getHasTriggeredEraseForNextIteration() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  short int mask = 1 << (3);
   short int tmp = static_cast<short int>(_packedRecords0 & mask);
   return (tmp != 0);
               }
               
               
               
               inline void setHasTriggeredEraseForNextIteration(const bool& hasTriggeredEraseForNextIteration) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  short int mask = 1 << (3);
   _packedRecords0 = static_cast<short int>( hasTriggeredEraseForNextIteration ? (_packedRecords0 | mask) : (_packedRecords0 & ~mask));
               }
               
               
               
               inline bool getHasChangedVertexOrCellState() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  short int mask = 1 << (4);
   short int tmp = static_cast<short int>(_packedRecords0 & mask);
   return (tmp != 0);
               }
               
               
               
               inline void setHasChangedVertexOrCellState(const bool& hasChangedVertexOrCellState) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  short int mask = 1 << (4);
   _packedRecords0 = static_cast<short int>( hasChangedVertexOrCellState ? (_packedRecords0 | mask) : (_packedRecords0 & ~mask));
               }
               
               
               
               inline bool getIsTraversalInverted() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _isTraversalInverted;
               }
               
               
               
               inline void setIsTraversalInverted(const bool& isTraversalInverted) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _isTraversalInverted = isTraversalInverted;
               }
               
               
               
               inline LoadBalancingState getLoadRebalancingState() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _loadRebalancingState;
               }
               
               
               
               inline void setLoadRebalancingState(const LoadBalancingState& loadRebalancingState) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _loadRebalancingState = loadRebalancingState;
               }
               
               
               
               inline bool getReduceStateAndCell() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  short int mask = 1 << (5);
   short int tmp = static_cast<short int>(_packedRecords0 & mask);
   return (tmp != 0);
               }
               
               
               
               inline void setReduceStateAndCell(const bool& reduceStateAndCell) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  short int mask = 1 << (5);
   _packedRecords0 = static_cast<short int>( reduceStateAndCell ? (_packedRecords0 | mask) : (_packedRecords0 & ~mask));
               }
               
               
               
            };
            
         private: 
            PersistentRecords _persistentRecords;
            
         public:
            /**
             * Generated
             */
            StatePacked();
            
            /**
             * Generated
             */
            StatePacked(const PersistentRecords& persistentRecords);
            
            /**
             * Generated
             */
            StatePacked(const double& updateUMax, const double& updateUH, const double& uMax, const double& uH, const int& timeStep, const double& timeStepSize, const double& time, const double& numberOfStencilUpdates, const int& globalPlotCounter, const tarch::la::Vector<DIMENSIONS,double>& minMeshWidth, const tarch::la::Vector<DIMENSIONS,double>& maxMeshWidth, const double& numberOfInnerVertices, const double& numberOfBoundaryVertices, const double& numberOfOuterVertices, const double& numberOfInnerCells, const double& numberOfOuterCells, const int& maxLevel, const bool& hasRefined, const bool& hasTriggeredRefinementForNextIteration, const bool& hasErased, const bool& hasTriggeredEraseForNextIteration, const bool& hasChangedVertexOrCellState, const bool& isTraversalInverted, const LoadBalancingState& loadRebalancingState, const bool& reduceStateAndCell);
            
            /**
             * Generated
             */
            virtual ~StatePacked();
            
            
            inline double getUpdateUMax() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _persistentRecords._updateUMax;
            }
            
            
            
            inline void setUpdateUMax(const double& updateUMax) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _persistentRecords._updateUMax = updateUMax;
            }
            
            
            
            inline double getUpdateUH() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _persistentRecords._updateUH;
            }
            
            
            
            inline void setUpdateUH(const double& updateUH) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _persistentRecords._updateUH = updateUH;
            }
            
            
            
            inline double getUMax() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _persistentRecords._uMax;
            }
            
            
            
            inline void setUMax(const double& uMax) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _persistentRecords._uMax = uMax;
            }
            
            
            
            inline double getUH() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _persistentRecords._uH;
            }
            
            
            
            inline void setUH(const double& uH) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _persistentRecords._uH = uH;
            }
            
            
            
            inline int getTimeStep() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _persistentRecords._timeStep;
            }
            
            
            
            inline void setTimeStep(const int& timeStep) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _persistentRecords._timeStep = timeStep;
            }
            
            
            
            inline double getTimeStepSize() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _persistentRecords._timeStepSize;
            }
            
            
            
            inline void setTimeStepSize(const double& timeStepSize) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _persistentRecords._timeStepSize = timeStepSize;
            }
            
            
            
            inline double getTime() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _persistentRecords._time;
            }
            
            
            
            inline void setTime(const double& time) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _persistentRecords._time = time;
            }
            
            
            
            inline double getNumberOfStencilUpdates() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _persistentRecords._numberOfStencilUpdates;
            }
            
            
            
            inline void setNumberOfStencilUpdates(const double& numberOfStencilUpdates) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _persistentRecords._numberOfStencilUpdates = numberOfStencilUpdates;
            }
            
            
            
            inline int getGlobalPlotCounter() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _persistentRecords._globalPlotCounter;
            }
            
            
            
            inline void setGlobalPlotCounter(const int& globalPlotCounter) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _persistentRecords._globalPlotCounter = globalPlotCounter;
            }
            
            
            
            /**
             * Generated and optimized
             * 
             * If you realise a for loop using exclusively arrays (vectors) and compile 
             * with -DUseManualAlignment you may add 
             * \code
             #pragma vector aligned
             #pragma simd
             \endcode to this for loop to enforce your compiler to use SSE/AVX.
             * 
             * The alignment is tied to the unpacked records, i.e. for packed class
             * variants the machine's natural alignment is switched off to recude the  
             * memory footprint. Do not use any SSE/AVX operations or 
             * vectorisation on the result for the packed variants, as the data is misaligned. 
             * If you rely on vectorisation, convert the underlying record 
             * into the unpacked version first. 
             * 
             * @see convert()
             */
            inline tarch::la::Vector<DIMENSIONS,double> getMinMeshWidth() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _persistentRecords._minMeshWidth;
            }
            
            
            
            /**
             * Generated and optimized
             * 
             * If you realise a for loop using exclusively arrays (vectors) and compile 
             * with -DUseManualAlignment you may add 
             * \code
             #pragma vector aligned
             #pragma simd
             \endcode to this for loop to enforce your compiler to use SSE/AVX.
             * 
             * The alignment is tied to the unpacked records, i.e. for packed class
             * variants the machine's natural alignment is switched off to recude the  
             * memory footprint. Do not use any SSE/AVX operations or 
             * vectorisation on the result for the packed variants, as the data is misaligned. 
             * If you rely on vectorisation, convert the underlying record 
             * into the unpacked version first. 
             * 
             * @see convert()
             */
            inline void setMinMeshWidth(const tarch::la::Vector<DIMENSIONS,double>& minMeshWidth) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _persistentRecords._minMeshWidth = (minMeshWidth);
            }
            
            
            
            inline double getMinMeshWidth(int elementIndex) const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               assertion(elementIndex>=0);
               assertion(elementIndex<DIMENSIONS);
               return _persistentRecords._minMeshWidth[elementIndex];
               
            }
            
            
            
            inline void setMinMeshWidth(int elementIndex, const double& minMeshWidth) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               assertion(elementIndex>=0);
               assertion(elementIndex<DIMENSIONS);
               _persistentRecords._minMeshWidth[elementIndex]= minMeshWidth;
               
            }
            
            
            
            /**
             * Generated and optimized
             * 
             * If you realise a for loop using exclusively arrays (vectors) and compile 
             * with -DUseManualAlignment you may add 
             * \code
             #pragma vector aligned
             #pragma simd
             \endcode to this for loop to enforce your compiler to use SSE/AVX.
             * 
             * The alignment is tied to the unpacked records, i.e. for packed class
             * variants the machine's natural alignment is switched off to recude the  
             * memory footprint. Do not use any SSE/AVX operations or 
             * vectorisation on the result for the packed variants, as the data is misaligned. 
             * If you rely on vectorisation, convert the underlying record 
             * into the unpacked version first. 
             * 
             * @see convert()
             */
            inline tarch::la::Vector<DIMENSIONS,double> getMaxMeshWidth() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _persistentRecords._maxMeshWidth;
            }
            
            
            
            /**
             * Generated and optimized
             * 
             * If you realise a for loop using exclusively arrays (vectors) and compile 
             * with -DUseManualAlignment you may add 
             * \code
             #pragma vector aligned
             #pragma simd
             \endcode to this for loop to enforce your compiler to use SSE/AVX.
             * 
             * The alignment is tied to the unpacked records, i.e. for packed class
             * variants the machine's natural alignment is switched off to recude the  
             * memory footprint. Do not use any SSE/AVX operations or 
             * vectorisation on the result for the packed variants, as the data is misaligned. 
             * If you rely on vectorisation, convert the underlying record 
             * into the unpacked version first. 
             * 
             * @see convert()
             */
            inline void setMaxMeshWidth(const tarch::la::Vector<DIMENSIONS,double>& maxMeshWidth) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _persistentRecords._maxMeshWidth = (maxMeshWidth);
            }
            
            
            
            inline double getMaxMeshWidth(int elementIndex) const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               assertion(elementIndex>=0);
               assertion(elementIndex<DIMENSIONS);
               return _persistentRecords._maxMeshWidth[elementIndex];
               
            }
            
            
            
            inline void setMaxMeshWidth(int elementIndex, const double& maxMeshWidth) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               assertion(elementIndex>=0);
               assertion(elementIndex<DIMENSIONS);
               _persistentRecords._maxMeshWidth[elementIndex]= maxMeshWidth;
               
            }
            
            
            
            inline double getNumberOfInnerVertices() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _persistentRecords._numberOfInnerVertices;
            }
            
            
            
            inline void setNumberOfInnerVertices(const double& numberOfInnerVertices) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _persistentRecords._numberOfInnerVertices = numberOfInnerVertices;
            }
            
            
            
            inline double getNumberOfBoundaryVertices() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _persistentRecords._numberOfBoundaryVertices;
            }
            
            
            
            inline void setNumberOfBoundaryVertices(const double& numberOfBoundaryVertices) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _persistentRecords._numberOfBoundaryVertices = numberOfBoundaryVertices;
            }
            
            
            
            inline double getNumberOfOuterVertices() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _persistentRecords._numberOfOuterVertices;
            }
            
            
            
            inline void setNumberOfOuterVertices(const double& numberOfOuterVertices) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _persistentRecords._numberOfOuterVertices = numberOfOuterVertices;
            }
            
            
            
            inline double getNumberOfInnerCells() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _persistentRecords._numberOfInnerCells;
            }
            
            
            
            inline void setNumberOfInnerCells(const double& numberOfInnerCells) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _persistentRecords._numberOfInnerCells = numberOfInnerCells;
            }
            
            
            
            inline double getNumberOfOuterCells() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _persistentRecords._numberOfOuterCells;
            }
            
            
            
            inline void setNumberOfOuterCells(const double& numberOfOuterCells) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _persistentRecords._numberOfOuterCells = numberOfOuterCells;
            }
            
            
            
            inline int getMaxLevel() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _persistentRecords._maxLevel;
            }
            
            
            
            inline void setMaxLevel(const int& maxLevel) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _persistentRecords._maxLevel = maxLevel;
            }
            
            
            
            inline bool getHasRefined() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               short int mask = 1 << (0);
   short int tmp = static_cast<short int>(_persistentRecords._packedRecords0 & mask);
   return (tmp != 0);
            }
            
            
            
            inline void setHasRefined(const bool& hasRefined) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               short int mask = 1 << (0);
   _persistentRecords._packedRecords0 = static_cast<short int>( hasRefined ? (_persistentRecords._packedRecords0 | mask) : (_persistentRecords._packedRecords0 & ~mask));
            }
            
            
            
            inline bool getHasTriggeredRefinementForNextIteration() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               short int mask = 1 << (1);
   short int tmp = static_cast<short int>(_persistentRecords._packedRecords0 & mask);
   return (tmp != 0);
            }
            
            
            
            inline void setHasTriggeredRefinementForNextIteration(const bool& hasTriggeredRefinementForNextIteration) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               short int mask = 1 << (1);
   _persistentRecords._packedRecords0 = static_cast<short int>( hasTriggeredRefinementForNextIteration ? (_persistentRecords._packedRecords0 | mask) : (_persistentRecords._packedRecords0 & ~mask));
            }
            
            
            
            inline bool getHasErased() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               short int mask = 1 << (2);
   short int tmp = static_cast<short int>(_persistentRecords._packedRecords0 & mask);
   return (tmp != 0);
            }
            
            
            
            inline void setHasErased(const bool& hasErased) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               short int mask = 1 << (2);
   _persistentRecords._packedRecords0 = static_cast<short int>( hasErased ? (_persistentRecords._packedRecords0 | mask) : (_persistentRecords._packedRecords0 & ~mask));
            }
            
            
            
            inline bool getHasTriggeredEraseForNextIteration() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               short int mask = 1 << (3);
   short int tmp = static_cast<short int>(_persistentRecords._packedRecords0 & mask);
   return (tmp != 0);
            }
            
            
            
            inline void setHasTriggeredEraseForNextIteration(const bool& hasTriggeredEraseForNextIteration) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               short int mask = 1 << (3);
   _persistentRecords._packedRecords0 = static_cast<short int>( hasTriggeredEraseForNextIteration ? (_persistentRecords._packedRecords0 | mask) : (_persistentRecords._packedRecords0 & ~mask));
            }
            
            
            
            inline bool getHasChangedVertexOrCellState() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               short int mask = 1 << (4);
   short int tmp = static_cast<short int>(_persistentRecords._packedRecords0 & mask);
   return (tmp != 0);
            }
            
            
            
            inline void setHasChangedVertexOrCellState(const bool& hasChangedVertexOrCellState) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               short int mask = 1 << (4);
   _persistentRecords._packedRecords0 = static_cast<short int>( hasChangedVertexOrCellState ? (_persistentRecords._packedRecords0 | mask) : (_persistentRecords._packedRecords0 & ~mask));
            }
            
            
            
            inline bool getIsTraversalInverted() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _persistentRecords._isTraversalInverted;
            }
            
            
            
            inline void setIsTraversalInverted(const bool& isTraversalInverted) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _persistentRecords._isTraversalInverted = isTraversalInverted;
            }
            
            
            
            inline LoadBalancingState getLoadRebalancingState() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               return _persistentRecords._loadRebalancingState;
            }
            
            
            
            inline void setLoadRebalancingState(const LoadBalancingState& loadRebalancingState) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               _persistentRecords._loadRebalancingState = loadRebalancingState;
            }
            
            
            
            inline bool getReduceStateAndCell() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               short int mask = 1 << (5);
   short int tmp = static_cast<short int>(_persistentRecords._packedRecords0 & mask);
   return (tmp != 0);
            }
            
            
            
            inline void setReduceStateAndCell(const bool& reduceStateAndCell) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
               short int mask = 1 << (5);
   _persistentRecords._packedRecords0 = static_cast<short int>( reduceStateAndCell ? (_persistentRecords._packedRecords0 | mask) : (_persistentRecords._packedRecords0 & ~mask));
            }
            
            
            /**
             * Generated
             */
            static std::string toString(const LoadBalancingState& param);
            
            /**
             * Generated
             */
            static std::string getLoadBalancingStateMapping();
            
            /**
             * Generated
             */
            std::string toString() const;
            
            /**
             * Generated
             */
            void toString(std::ostream& out) const;
            
            
            PersistentRecords getPersistentRecords() const;
            /**
             * Generated
             */
            State convert() const;
            
            
         #ifdef Parallel
            protected:
               static tarch::logging::Log _log;
               
               int _senderDestinationRank;
               
            public:
               
               /**
                * Global that represents the mpi datatype.
                * There are two variants: Datatype identifies only those attributes marked with
                * parallelise. FullDatatype instead identifies the whole record with all fields.
                */
               static MPI_Datatype Datatype;
               static MPI_Datatype FullDatatype;
               
               /**
                * Initializes the data type for the mpi operations. Has to be called
                * before the very first send or receive operation is called.
                */
               static void initDatatype();
               
               static void shutdownDatatype();
               
               void send(int destination, int tag, bool exchangeOnlyAttributesMarkedWithParallelise);
               
               void receive(int source, int tag, bool exchangeOnlyAttributesMarkedWithParallelise);
               
               static bool isMessageInQueue(int tag, bool exchangeOnlyAttributesMarkedWithParallelise);
               
               int getSenderRank() const;
               
         #endif
            
         };
         
         #ifdef PackedRecords
         #pragma pack (pop)
         #endif
         
         
         
      #elif !defined(Parallel)
         /**
          * @author This class is generated by DaStGen
          * 		   DataStructureGenerator (DaStGen)
          * 		   2007-2009 Wolfgang Eckhardt
          * 		   2012      Tobias Weinzierl
          *
          * 		   build date: 20-02-2013 11:21
          *
          * @date   02/04/2013 15:53
          */
         class rotatingheatsource::expliciteuler::records::State { 
            
            public:
               
               typedef rotatingheatsource::expliciteuler::records::StatePacked Packed;
               
               struct PersistentRecords {
                  double _updateUMax;
                  double _updateUH;
                  double _uMax;
                  double _uH;
                  int _timeStep;
                  double _timeStepSize;
                  double _time;
                  double _numberOfStencilUpdates;
                  int _globalPlotCounter;
                  #ifdef UseManualAlignment
                  tarch::la::Vector<DIMENSIONS,double> _minMeshWidth __attribute__((aligned(VectorisationAlignment)));
                  #else
                  tarch::la::Vector<DIMENSIONS,double> _minMeshWidth;
                  #endif
                  #ifdef UseManualAlignment
                  tarch::la::Vector<DIMENSIONS,double> _maxMeshWidth __attribute__((aligned(VectorisationAlignment)));
                  #else
                  tarch::la::Vector<DIMENSIONS,double> _maxMeshWidth;
                  #endif
                  double _numberOfInnerVertices;
                  double _numberOfBoundaryVertices;
                  double _numberOfOuterVertices;
                  double _numberOfInnerCells;
                  double _numberOfOuterCells;
                  int _maxLevel;
                  bool _hasRefined;
                  bool _hasTriggeredRefinementForNextIteration;
                  bool _hasErased;
                  bool _hasTriggeredEraseForNextIteration;
                  bool _hasChangedVertexOrCellState;
                  bool _isTraversalInverted;
                  /**
                   * Generated
                   */
                  PersistentRecords();
                  
                  /**
                   * Generated
                   */
                  PersistentRecords(const double& updateUMax, const double& updateUH, const double& uMax, const double& uH, const int& timeStep, const double& timeStepSize, const double& time, const double& numberOfStencilUpdates, const int& globalPlotCounter, const tarch::la::Vector<DIMENSIONS,double>& minMeshWidth, const tarch::la::Vector<DIMENSIONS,double>& maxMeshWidth, const double& numberOfInnerVertices, const double& numberOfBoundaryVertices, const double& numberOfOuterVertices, const double& numberOfInnerCells, const double& numberOfOuterCells, const int& maxLevel, const bool& hasRefined, const bool& hasTriggeredRefinementForNextIteration, const bool& hasErased, const bool& hasTriggeredEraseForNextIteration, const bool& hasChangedVertexOrCellState, const bool& isTraversalInverted);
                  
                  
                  inline double getUpdateUMax() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _updateUMax;
                  }
                  
                  
                  
                  inline void setUpdateUMax(const double& updateUMax) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _updateUMax = updateUMax;
                  }
                  
                  
                  
                  inline double getUpdateUH() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _updateUH;
                  }
                  
                  
                  
                  inline void setUpdateUH(const double& updateUH) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _updateUH = updateUH;
                  }
                  
                  
                  
                  inline double getUMax() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _uMax;
                  }
                  
                  
                  
                  inline void setUMax(const double& uMax) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _uMax = uMax;
                  }
                  
                  
                  
                  inline double getUH() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _uH;
                  }
                  
                  
                  
                  inline void setUH(const double& uH) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _uH = uH;
                  }
                  
                  
                  
                  inline int getTimeStep() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _timeStep;
                  }
                  
                  
                  
                  inline void setTimeStep(const int& timeStep) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _timeStep = timeStep;
                  }
                  
                  
                  
                  inline double getTimeStepSize() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _timeStepSize;
                  }
                  
                  
                  
                  inline void setTimeStepSize(const double& timeStepSize) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _timeStepSize = timeStepSize;
                  }
                  
                  
                  
                  inline double getTime() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _time;
                  }
                  
                  
                  
                  inline void setTime(const double& time) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _time = time;
                  }
                  
                  
                  
                  inline double getNumberOfStencilUpdates() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _numberOfStencilUpdates;
                  }
                  
                  
                  
                  inline void setNumberOfStencilUpdates(const double& numberOfStencilUpdates) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _numberOfStencilUpdates = numberOfStencilUpdates;
                  }
                  
                  
                  
                  inline int getGlobalPlotCounter() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _globalPlotCounter;
                  }
                  
                  
                  
                  inline void setGlobalPlotCounter(const int& globalPlotCounter) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _globalPlotCounter = globalPlotCounter;
                  }
                  
                  
                  
                  /**
                   * Generated and optimized
                   * 
                   * If you realise a for loop using exclusively arrays (vectors) and compile 
                   * with -DUseManualAlignment you may add 
                   * \code
                   #pragma vector aligned
                   #pragma simd
                   \endcode to this for loop to enforce your compiler to use SSE/AVX.
                   * 
                   * The alignment is tied to the unpacked records, i.e. for packed class
                   * variants the machine's natural alignment is switched off to recude the  
                   * memory footprint. Do not use any SSE/AVX operations or 
                   * vectorisation on the result for the packed variants, as the data is misaligned. 
                   * If you rely on vectorisation, convert the underlying record 
                   * into the unpacked version first. 
                   * 
                   * @see convert()
                   */
                  inline tarch::la::Vector<DIMENSIONS,double> getMinMeshWidth() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _minMeshWidth;
                  }
                  
                  
                  
                  /**
                   * Generated and optimized
                   * 
                   * If you realise a for loop using exclusively arrays (vectors) and compile 
                   * with -DUseManualAlignment you may add 
                   * \code
                   #pragma vector aligned
                   #pragma simd
                   \endcode to this for loop to enforce your compiler to use SSE/AVX.
                   * 
                   * The alignment is tied to the unpacked records, i.e. for packed class
                   * variants the machine's natural alignment is switched off to recude the  
                   * memory footprint. Do not use any SSE/AVX operations or 
                   * vectorisation on the result for the packed variants, as the data is misaligned. 
                   * If you rely on vectorisation, convert the underlying record 
                   * into the unpacked version first. 
                   * 
                   * @see convert()
                   */
                  inline void setMinMeshWidth(const tarch::la::Vector<DIMENSIONS,double>& minMeshWidth) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _minMeshWidth = (minMeshWidth);
                  }
                  
                  
                  
                  /**
                   * Generated and optimized
                   * 
                   * If you realise a for loop using exclusively arrays (vectors) and compile 
                   * with -DUseManualAlignment you may add 
                   * \code
                   #pragma vector aligned
                   #pragma simd
                   \endcode to this for loop to enforce your compiler to use SSE/AVX.
                   * 
                   * The alignment is tied to the unpacked records, i.e. for packed class
                   * variants the machine's natural alignment is switched off to recude the  
                   * memory footprint. Do not use any SSE/AVX operations or 
                   * vectorisation on the result for the packed variants, as the data is misaligned. 
                   * If you rely on vectorisation, convert the underlying record 
                   * into the unpacked version first. 
                   * 
                   * @see convert()
                   */
                  inline tarch::la::Vector<DIMENSIONS,double> getMaxMeshWidth() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _maxMeshWidth;
                  }
                  
                  
                  
                  /**
                   * Generated and optimized
                   * 
                   * If you realise a for loop using exclusively arrays (vectors) and compile 
                   * with -DUseManualAlignment you may add 
                   * \code
                   #pragma vector aligned
                   #pragma simd
                   \endcode to this for loop to enforce your compiler to use SSE/AVX.
                   * 
                   * The alignment is tied to the unpacked records, i.e. for packed class
                   * variants the machine's natural alignment is switched off to recude the  
                   * memory footprint. Do not use any SSE/AVX operations or 
                   * vectorisation on the result for the packed variants, as the data is misaligned. 
                   * If you rely on vectorisation, convert the underlying record 
                   * into the unpacked version first. 
                   * 
                   * @see convert()
                   */
                  inline void setMaxMeshWidth(const tarch::la::Vector<DIMENSIONS,double>& maxMeshWidth) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _maxMeshWidth = (maxMeshWidth);
                  }
                  
                  
                  
                  inline double getNumberOfInnerVertices() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _numberOfInnerVertices;
                  }
                  
                  
                  
                  inline void setNumberOfInnerVertices(const double& numberOfInnerVertices) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _numberOfInnerVertices = numberOfInnerVertices;
                  }
                  
                  
                  
                  inline double getNumberOfBoundaryVertices() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _numberOfBoundaryVertices;
                  }
                  
                  
                  
                  inline void setNumberOfBoundaryVertices(const double& numberOfBoundaryVertices) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _numberOfBoundaryVertices = numberOfBoundaryVertices;
                  }
                  
                  
                  
                  inline double getNumberOfOuterVertices() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _numberOfOuterVertices;
                  }
                  
                  
                  
                  inline void setNumberOfOuterVertices(const double& numberOfOuterVertices) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _numberOfOuterVertices = numberOfOuterVertices;
                  }
                  
                  
                  
                  inline double getNumberOfInnerCells() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _numberOfInnerCells;
                  }
                  
                  
                  
                  inline void setNumberOfInnerCells(const double& numberOfInnerCells) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _numberOfInnerCells = numberOfInnerCells;
                  }
                  
                  
                  
                  inline double getNumberOfOuterCells() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _numberOfOuterCells;
                  }
                  
                  
                  
                  inline void setNumberOfOuterCells(const double& numberOfOuterCells) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _numberOfOuterCells = numberOfOuterCells;
                  }
                  
                  
                  
                  inline int getMaxLevel() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _maxLevel;
                  }
                  
                  
                  
                  inline void setMaxLevel(const int& maxLevel) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _maxLevel = maxLevel;
                  }
                  
                  
                  
                  inline bool getHasRefined() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _hasRefined;
                  }
                  
                  
                  
                  inline void setHasRefined(const bool& hasRefined) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _hasRefined = hasRefined;
                  }
                  
                  
                  
                  inline bool getHasTriggeredRefinementForNextIteration() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _hasTriggeredRefinementForNextIteration;
                  }
                  
                  
                  
                  inline void setHasTriggeredRefinementForNextIteration(const bool& hasTriggeredRefinementForNextIteration) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _hasTriggeredRefinementForNextIteration = hasTriggeredRefinementForNextIteration;
                  }
                  
                  
                  
                  inline bool getHasErased() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _hasErased;
                  }
                  
                  
                  
                  inline void setHasErased(const bool& hasErased) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _hasErased = hasErased;
                  }
                  
                  
                  
                  inline bool getHasTriggeredEraseForNextIteration() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _hasTriggeredEraseForNextIteration;
                  }
                  
                  
                  
                  inline void setHasTriggeredEraseForNextIteration(const bool& hasTriggeredEraseForNextIteration) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _hasTriggeredEraseForNextIteration = hasTriggeredEraseForNextIteration;
                  }
                  
                  
                  
                  inline bool getHasChangedVertexOrCellState() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _hasChangedVertexOrCellState;
                  }
                  
                  
                  
                  inline void setHasChangedVertexOrCellState(const bool& hasChangedVertexOrCellState) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _hasChangedVertexOrCellState = hasChangedVertexOrCellState;
                  }
                  
                  
                  
                  inline bool getIsTraversalInverted() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _isTraversalInverted;
                  }
                  
                  
                  
                  inline void setIsTraversalInverted(const bool& isTraversalInverted) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _isTraversalInverted = isTraversalInverted;
                  }
                  
                  
                  
               };
               
            private: 
               PersistentRecords _persistentRecords;
               
            public:
               /**
                * Generated
                */
               State();
               
               /**
                * Generated
                */
               State(const PersistentRecords& persistentRecords);
               
               /**
                * Generated
                */
               State(const double& updateUMax, const double& updateUH, const double& uMax, const double& uH, const int& timeStep, const double& timeStepSize, const double& time, const double& numberOfStencilUpdates, const int& globalPlotCounter, const tarch::la::Vector<DIMENSIONS,double>& minMeshWidth, const tarch::la::Vector<DIMENSIONS,double>& maxMeshWidth, const double& numberOfInnerVertices, const double& numberOfBoundaryVertices, const double& numberOfOuterVertices, const double& numberOfInnerCells, const double& numberOfOuterCells, const int& maxLevel, const bool& hasRefined, const bool& hasTriggeredRefinementForNextIteration, const bool& hasErased, const bool& hasTriggeredEraseForNextIteration, const bool& hasChangedVertexOrCellState, const bool& isTraversalInverted);
               
               /**
                * Generated
                */
               virtual ~State();
               
               
               inline double getUpdateUMax() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _persistentRecords._updateUMax;
               }
               
               
               
               inline void setUpdateUMax(const double& updateUMax) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _persistentRecords._updateUMax = updateUMax;
               }
               
               
               
               inline double getUpdateUH() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _persistentRecords._updateUH;
               }
               
               
               
               inline void setUpdateUH(const double& updateUH) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _persistentRecords._updateUH = updateUH;
               }
               
               
               
               inline double getUMax() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _persistentRecords._uMax;
               }
               
               
               
               inline void setUMax(const double& uMax) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _persistentRecords._uMax = uMax;
               }
               
               
               
               inline double getUH() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _persistentRecords._uH;
               }
               
               
               
               inline void setUH(const double& uH) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _persistentRecords._uH = uH;
               }
               
               
               
               inline int getTimeStep() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _persistentRecords._timeStep;
               }
               
               
               
               inline void setTimeStep(const int& timeStep) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _persistentRecords._timeStep = timeStep;
               }
               
               
               
               inline double getTimeStepSize() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _persistentRecords._timeStepSize;
               }
               
               
               
               inline void setTimeStepSize(const double& timeStepSize) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _persistentRecords._timeStepSize = timeStepSize;
               }
               
               
               
               inline double getTime() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _persistentRecords._time;
               }
               
               
               
               inline void setTime(const double& time) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _persistentRecords._time = time;
               }
               
               
               
               inline double getNumberOfStencilUpdates() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _persistentRecords._numberOfStencilUpdates;
               }
               
               
               
               inline void setNumberOfStencilUpdates(const double& numberOfStencilUpdates) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _persistentRecords._numberOfStencilUpdates = numberOfStencilUpdates;
               }
               
               
               
               inline int getGlobalPlotCounter() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _persistentRecords._globalPlotCounter;
               }
               
               
               
               inline void setGlobalPlotCounter(const int& globalPlotCounter) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _persistentRecords._globalPlotCounter = globalPlotCounter;
               }
               
               
               
               /**
                * Generated and optimized
                * 
                * If you realise a for loop using exclusively arrays (vectors) and compile 
                * with -DUseManualAlignment you may add 
                * \code
                #pragma vector aligned
                #pragma simd
                \endcode to this for loop to enforce your compiler to use SSE/AVX.
                * 
                * The alignment is tied to the unpacked records, i.e. for packed class
                * variants the machine's natural alignment is switched off to recude the  
                * memory footprint. Do not use any SSE/AVX operations or 
                * vectorisation on the result for the packed variants, as the data is misaligned. 
                * If you rely on vectorisation, convert the underlying record 
                * into the unpacked version first. 
                * 
                * @see convert()
                */
               inline tarch::la::Vector<DIMENSIONS,double> getMinMeshWidth() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _persistentRecords._minMeshWidth;
               }
               
               
               
               /**
                * Generated and optimized
                * 
                * If you realise a for loop using exclusively arrays (vectors) and compile 
                * with -DUseManualAlignment you may add 
                * \code
                #pragma vector aligned
                #pragma simd
                \endcode to this for loop to enforce your compiler to use SSE/AVX.
                * 
                * The alignment is tied to the unpacked records, i.e. for packed class
                * variants the machine's natural alignment is switched off to recude the  
                * memory footprint. Do not use any SSE/AVX operations or 
                * vectorisation on the result for the packed variants, as the data is misaligned. 
                * If you rely on vectorisation, convert the underlying record 
                * into the unpacked version first. 
                * 
                * @see convert()
                */
               inline void setMinMeshWidth(const tarch::la::Vector<DIMENSIONS,double>& minMeshWidth) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _persistentRecords._minMeshWidth = (minMeshWidth);
               }
               
               
               
               inline double getMinMeshWidth(int elementIndex) const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  assertion(elementIndex>=0);
                  assertion(elementIndex<DIMENSIONS);
                  return _persistentRecords._minMeshWidth[elementIndex];
                  
               }
               
               
               
               inline void setMinMeshWidth(int elementIndex, const double& minMeshWidth) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  assertion(elementIndex>=0);
                  assertion(elementIndex<DIMENSIONS);
                  _persistentRecords._minMeshWidth[elementIndex]= minMeshWidth;
                  
               }
               
               
               
               /**
                * Generated and optimized
                * 
                * If you realise a for loop using exclusively arrays (vectors) and compile 
                * with -DUseManualAlignment you may add 
                * \code
                #pragma vector aligned
                #pragma simd
                \endcode to this for loop to enforce your compiler to use SSE/AVX.
                * 
                * The alignment is tied to the unpacked records, i.e. for packed class
                * variants the machine's natural alignment is switched off to recude the  
                * memory footprint. Do not use any SSE/AVX operations or 
                * vectorisation on the result for the packed variants, as the data is misaligned. 
                * If you rely on vectorisation, convert the underlying record 
                * into the unpacked version first. 
                * 
                * @see convert()
                */
               inline tarch::la::Vector<DIMENSIONS,double> getMaxMeshWidth() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _persistentRecords._maxMeshWidth;
               }
               
               
               
               /**
                * Generated and optimized
                * 
                * If you realise a for loop using exclusively arrays (vectors) and compile 
                * with -DUseManualAlignment you may add 
                * \code
                #pragma vector aligned
                #pragma simd
                \endcode to this for loop to enforce your compiler to use SSE/AVX.
                * 
                * The alignment is tied to the unpacked records, i.e. for packed class
                * variants the machine's natural alignment is switched off to recude the  
                * memory footprint. Do not use any SSE/AVX operations or 
                * vectorisation on the result for the packed variants, as the data is misaligned. 
                * If you rely on vectorisation, convert the underlying record 
                * into the unpacked version first. 
                * 
                * @see convert()
                */
               inline void setMaxMeshWidth(const tarch::la::Vector<DIMENSIONS,double>& maxMeshWidth) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _persistentRecords._maxMeshWidth = (maxMeshWidth);
               }
               
               
               
               inline double getMaxMeshWidth(int elementIndex) const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  assertion(elementIndex>=0);
                  assertion(elementIndex<DIMENSIONS);
                  return _persistentRecords._maxMeshWidth[elementIndex];
                  
               }
               
               
               
               inline void setMaxMeshWidth(int elementIndex, const double& maxMeshWidth) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  assertion(elementIndex>=0);
                  assertion(elementIndex<DIMENSIONS);
                  _persistentRecords._maxMeshWidth[elementIndex]= maxMeshWidth;
                  
               }
               
               
               
               inline double getNumberOfInnerVertices() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _persistentRecords._numberOfInnerVertices;
               }
               
               
               
               inline void setNumberOfInnerVertices(const double& numberOfInnerVertices) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _persistentRecords._numberOfInnerVertices = numberOfInnerVertices;
               }
               
               
               
               inline double getNumberOfBoundaryVertices() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _persistentRecords._numberOfBoundaryVertices;
               }
               
               
               
               inline void setNumberOfBoundaryVertices(const double& numberOfBoundaryVertices) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _persistentRecords._numberOfBoundaryVertices = numberOfBoundaryVertices;
               }
               
               
               
               inline double getNumberOfOuterVertices() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _persistentRecords._numberOfOuterVertices;
               }
               
               
               
               inline void setNumberOfOuterVertices(const double& numberOfOuterVertices) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _persistentRecords._numberOfOuterVertices = numberOfOuterVertices;
               }
               
               
               
               inline double getNumberOfInnerCells() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _persistentRecords._numberOfInnerCells;
               }
               
               
               
               inline void setNumberOfInnerCells(const double& numberOfInnerCells) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _persistentRecords._numberOfInnerCells = numberOfInnerCells;
               }
               
               
               
               inline double getNumberOfOuterCells() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _persistentRecords._numberOfOuterCells;
               }
               
               
               
               inline void setNumberOfOuterCells(const double& numberOfOuterCells) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _persistentRecords._numberOfOuterCells = numberOfOuterCells;
               }
               
               
               
               inline int getMaxLevel() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _persistentRecords._maxLevel;
               }
               
               
               
               inline void setMaxLevel(const int& maxLevel) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _persistentRecords._maxLevel = maxLevel;
               }
               
               
               
               inline bool getHasRefined() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _persistentRecords._hasRefined;
               }
               
               
               
               inline void setHasRefined(const bool& hasRefined) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _persistentRecords._hasRefined = hasRefined;
               }
               
               
               
               inline bool getHasTriggeredRefinementForNextIteration() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _persistentRecords._hasTriggeredRefinementForNextIteration;
               }
               
               
               
               inline void setHasTriggeredRefinementForNextIteration(const bool& hasTriggeredRefinementForNextIteration) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _persistentRecords._hasTriggeredRefinementForNextIteration = hasTriggeredRefinementForNextIteration;
               }
               
               
               
               inline bool getHasErased() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _persistentRecords._hasErased;
               }
               
               
               
               inline void setHasErased(const bool& hasErased) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _persistentRecords._hasErased = hasErased;
               }
               
               
               
               inline bool getHasTriggeredEraseForNextIteration() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _persistentRecords._hasTriggeredEraseForNextIteration;
               }
               
               
               
               inline void setHasTriggeredEraseForNextIteration(const bool& hasTriggeredEraseForNextIteration) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _persistentRecords._hasTriggeredEraseForNextIteration = hasTriggeredEraseForNextIteration;
               }
               
               
               
               inline bool getHasChangedVertexOrCellState() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _persistentRecords._hasChangedVertexOrCellState;
               }
               
               
               
               inline void setHasChangedVertexOrCellState(const bool& hasChangedVertexOrCellState) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _persistentRecords._hasChangedVertexOrCellState = hasChangedVertexOrCellState;
               }
               
               
               
               inline bool getIsTraversalInverted() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  return _persistentRecords._isTraversalInverted;
               }
               
               
               
               inline void setIsTraversalInverted(const bool& isTraversalInverted) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                  _persistentRecords._isTraversalInverted = isTraversalInverted;
               }
               
               
               /**
                * Generated
                */
               std::string toString() const;
               
               /**
                * Generated
                */
               void toString(std::ostream& out) const;
               
               
               PersistentRecords getPersistentRecords() const;
               /**
                * Generated
                */
               StatePacked convert() const;
               
               
            #ifdef Parallel
               protected:
                  static tarch::logging::Log _log;
                  
                  int _senderDestinationRank;
                  
               public:
                  
                  /**
                   * Global that represents the mpi datatype.
                   * There are two variants: Datatype identifies only those attributes marked with
                   * parallelise. FullDatatype instead identifies the whole record with all fields.
                   */
                  static MPI_Datatype Datatype;
                  static MPI_Datatype FullDatatype;
                  
                  /**
                   * Initializes the data type for the mpi operations. Has to be called
                   * before the very first send or receive operation is called.
                   */
                  static void initDatatype();
                  
                  static void shutdownDatatype();
                  
                  void send(int destination, int tag, bool exchangeOnlyAttributesMarkedWithParallelise);
                  
                  void receive(int source, int tag, bool exchangeOnlyAttributesMarkedWithParallelise);
                  
                  static bool isMessageInQueue(int tag, bool exchangeOnlyAttributesMarkedWithParallelise);
                  
                  int getSenderRank() const;
                  
            #endif
               
            };
            
            #ifndef DaStGenPackedPadding
              #define DaStGenPackedPadding 1      // 32 bit version
              // #define DaStGenPackedPadding 2   // 64 bit version
            #endif
            
            
            #ifdef PackedRecords
               #pragma pack (push, DaStGenPackedPadding)
            #endif
            
            /**
             * @author This class is generated by DaStGen
             * 		   DataStructureGenerator (DaStGen)
             * 		   2007-2009 Wolfgang Eckhardt
             * 		   2012      Tobias Weinzierl
             *
             * 		   build date: 20-02-2013 11:21
             *
             * @date   02/04/2013 15:53
             */
            class rotatingheatsource::expliciteuler::records::StatePacked { 
               
               public:
                  
                  struct PersistentRecords {
                     double _updateUMax;
                     double _updateUH;
                     double _uMax;
                     double _uH;
                     int _timeStep;
                     double _timeStepSize;
                     double _time;
                     double _numberOfStencilUpdates;
                     int _globalPlotCounter;
                     tarch::la::Vector<DIMENSIONS,double> _minMeshWidth;
                     tarch::la::Vector<DIMENSIONS,double> _maxMeshWidth;
                     double _numberOfInnerVertices;
                     double _numberOfBoundaryVertices;
                     double _numberOfOuterVertices;
                     double _numberOfInnerCells;
                     double _numberOfOuterCells;
                     int _maxLevel;
                     bool _isTraversalInverted;
                     
                     /** mapping of records:
                     || Member 	|| startbit 	|| length
                      |  hasRefined	| startbit 0	| #bits 1
                      |  hasTriggeredRefinementForNextIteration	| startbit 1	| #bits 1
                      |  hasErased	| startbit 2	| #bits 1
                      |  hasTriggeredEraseForNextIteration	| startbit 3	| #bits 1
                      |  hasChangedVertexOrCellState	| startbit 4	| #bits 1
                      */
                     short int _packedRecords0;
                     
                     /**
                      * Generated
                      */
                     PersistentRecords();
                     
                     /**
                      * Generated
                      */
                     PersistentRecords(const double& updateUMax, const double& updateUH, const double& uMax, const double& uH, const int& timeStep, const double& timeStepSize, const double& time, const double& numberOfStencilUpdates, const int& globalPlotCounter, const tarch::la::Vector<DIMENSIONS,double>& minMeshWidth, const tarch::la::Vector<DIMENSIONS,double>& maxMeshWidth, const double& numberOfInnerVertices, const double& numberOfBoundaryVertices, const double& numberOfOuterVertices, const double& numberOfInnerCells, const double& numberOfOuterCells, const int& maxLevel, const bool& hasRefined, const bool& hasTriggeredRefinementForNextIteration, const bool& hasErased, const bool& hasTriggeredEraseForNextIteration, const bool& hasChangedVertexOrCellState, const bool& isTraversalInverted);
                     
                     
                     inline double getUpdateUMax() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        return _updateUMax;
                     }
                     
                     
                     
                     inline void setUpdateUMax(const double& updateUMax) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        _updateUMax = updateUMax;
                     }
                     
                     
                     
                     inline double getUpdateUH() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        return _updateUH;
                     }
                     
                     
                     
                     inline void setUpdateUH(const double& updateUH) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        _updateUH = updateUH;
                     }
                     
                     
                     
                     inline double getUMax() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        return _uMax;
                     }
                     
                     
                     
                     inline void setUMax(const double& uMax) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        _uMax = uMax;
                     }
                     
                     
                     
                     inline double getUH() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        return _uH;
                     }
                     
                     
                     
                     inline void setUH(const double& uH) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        _uH = uH;
                     }
                     
                     
                     
                     inline int getTimeStep() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        return _timeStep;
                     }
                     
                     
                     
                     inline void setTimeStep(const int& timeStep) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        _timeStep = timeStep;
                     }
                     
                     
                     
                     inline double getTimeStepSize() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        return _timeStepSize;
                     }
                     
                     
                     
                     inline void setTimeStepSize(const double& timeStepSize) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        _timeStepSize = timeStepSize;
                     }
                     
                     
                     
                     inline double getTime() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        return _time;
                     }
                     
                     
                     
                     inline void setTime(const double& time) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        _time = time;
                     }
                     
                     
                     
                     inline double getNumberOfStencilUpdates() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        return _numberOfStencilUpdates;
                     }
                     
                     
                     
                     inline void setNumberOfStencilUpdates(const double& numberOfStencilUpdates) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        _numberOfStencilUpdates = numberOfStencilUpdates;
                     }
                     
                     
                     
                     inline int getGlobalPlotCounter() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        return _globalPlotCounter;
                     }
                     
                     
                     
                     inline void setGlobalPlotCounter(const int& globalPlotCounter) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        _globalPlotCounter = globalPlotCounter;
                     }
                     
                     
                     
                     /**
                      * Generated and optimized
                      * 
                      * If you realise a for loop using exclusively arrays (vectors) and compile 
                      * with -DUseManualAlignment you may add 
                      * \code
                      #pragma vector aligned
                      #pragma simd
                      \endcode to this for loop to enforce your compiler to use SSE/AVX.
                      * 
                      * The alignment is tied to the unpacked records, i.e. for packed class
                      * variants the machine's natural alignment is switched off to recude the  
                      * memory footprint. Do not use any SSE/AVX operations or 
                      * vectorisation on the result for the packed variants, as the data is misaligned. 
                      * If you rely on vectorisation, convert the underlying record 
                      * into the unpacked version first. 
                      * 
                      * @see convert()
                      */
                     inline tarch::la::Vector<DIMENSIONS,double> getMinMeshWidth() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        return _minMeshWidth;
                     }
                     
                     
                     
                     /**
                      * Generated and optimized
                      * 
                      * If you realise a for loop using exclusively arrays (vectors) and compile 
                      * with -DUseManualAlignment you may add 
                      * \code
                      #pragma vector aligned
                      #pragma simd
                      \endcode to this for loop to enforce your compiler to use SSE/AVX.
                      * 
                      * The alignment is tied to the unpacked records, i.e. for packed class
                      * variants the machine's natural alignment is switched off to recude the  
                      * memory footprint. Do not use any SSE/AVX operations or 
                      * vectorisation on the result for the packed variants, as the data is misaligned. 
                      * If you rely on vectorisation, convert the underlying record 
                      * into the unpacked version first. 
                      * 
                      * @see convert()
                      */
                     inline void setMinMeshWidth(const tarch::la::Vector<DIMENSIONS,double>& minMeshWidth) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        _minMeshWidth = (minMeshWidth);
                     }
                     
                     
                     
                     /**
                      * Generated and optimized
                      * 
                      * If you realise a for loop using exclusively arrays (vectors) and compile 
                      * with -DUseManualAlignment you may add 
                      * \code
                      #pragma vector aligned
                      #pragma simd
                      \endcode to this for loop to enforce your compiler to use SSE/AVX.
                      * 
                      * The alignment is tied to the unpacked records, i.e. for packed class
                      * variants the machine's natural alignment is switched off to recude the  
                      * memory footprint. Do not use any SSE/AVX operations or 
                      * vectorisation on the result for the packed variants, as the data is misaligned. 
                      * If you rely on vectorisation, convert the underlying record 
                      * into the unpacked version first. 
                      * 
                      * @see convert()
                      */
                     inline tarch::la::Vector<DIMENSIONS,double> getMaxMeshWidth() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        return _maxMeshWidth;
                     }
                     
                     
                     
                     /**
                      * Generated and optimized
                      * 
                      * If you realise a for loop using exclusively arrays (vectors) and compile 
                      * with -DUseManualAlignment you may add 
                      * \code
                      #pragma vector aligned
                      #pragma simd
                      \endcode to this for loop to enforce your compiler to use SSE/AVX.
                      * 
                      * The alignment is tied to the unpacked records, i.e. for packed class
                      * variants the machine's natural alignment is switched off to recude the  
                      * memory footprint. Do not use any SSE/AVX operations or 
                      * vectorisation on the result for the packed variants, as the data is misaligned. 
                      * If you rely on vectorisation, convert the underlying record 
                      * into the unpacked version first. 
                      * 
                      * @see convert()
                      */
                     inline void setMaxMeshWidth(const tarch::la::Vector<DIMENSIONS,double>& maxMeshWidth) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        _maxMeshWidth = (maxMeshWidth);
                     }
                     
                     
                     
                     inline double getNumberOfInnerVertices() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        return _numberOfInnerVertices;
                     }
                     
                     
                     
                     inline void setNumberOfInnerVertices(const double& numberOfInnerVertices) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        _numberOfInnerVertices = numberOfInnerVertices;
                     }
                     
                     
                     
                     inline double getNumberOfBoundaryVertices() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        return _numberOfBoundaryVertices;
                     }
                     
                     
                     
                     inline void setNumberOfBoundaryVertices(const double& numberOfBoundaryVertices) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        _numberOfBoundaryVertices = numberOfBoundaryVertices;
                     }
                     
                     
                     
                     inline double getNumberOfOuterVertices() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        return _numberOfOuterVertices;
                     }
                     
                     
                     
                     inline void setNumberOfOuterVertices(const double& numberOfOuterVertices) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        _numberOfOuterVertices = numberOfOuterVertices;
                     }
                     
                     
                     
                     inline double getNumberOfInnerCells() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        return _numberOfInnerCells;
                     }
                     
                     
                     
                     inline void setNumberOfInnerCells(const double& numberOfInnerCells) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        _numberOfInnerCells = numberOfInnerCells;
                     }
                     
                     
                     
                     inline double getNumberOfOuterCells() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        return _numberOfOuterCells;
                     }
                     
                     
                     
                     inline void setNumberOfOuterCells(const double& numberOfOuterCells) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        _numberOfOuterCells = numberOfOuterCells;
                     }
                     
                     
                     
                     inline int getMaxLevel() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        return _maxLevel;
                     }
                     
                     
                     
                     inline void setMaxLevel(const int& maxLevel) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        _maxLevel = maxLevel;
                     }
                     
                     
                     
                     inline bool getHasRefined() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        short int mask = 1 << (0);
   short int tmp = static_cast<short int>(_packedRecords0 & mask);
   return (tmp != 0);
                     }
                     
                     
                     
                     inline void setHasRefined(const bool& hasRefined) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        short int mask = 1 << (0);
   _packedRecords0 = static_cast<short int>( hasRefined ? (_packedRecords0 | mask) : (_packedRecords0 & ~mask));
                     }
                     
                     
                     
                     inline bool getHasTriggeredRefinementForNextIteration() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        short int mask = 1 << (1);
   short int tmp = static_cast<short int>(_packedRecords0 & mask);
   return (tmp != 0);
                     }
                     
                     
                     
                     inline void setHasTriggeredRefinementForNextIteration(const bool& hasTriggeredRefinementForNextIteration) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        short int mask = 1 << (1);
   _packedRecords0 = static_cast<short int>( hasTriggeredRefinementForNextIteration ? (_packedRecords0 | mask) : (_packedRecords0 & ~mask));
                     }
                     
                     
                     
                     inline bool getHasErased() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        short int mask = 1 << (2);
   short int tmp = static_cast<short int>(_packedRecords0 & mask);
   return (tmp != 0);
                     }
                     
                     
                     
                     inline void setHasErased(const bool& hasErased) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        short int mask = 1 << (2);
   _packedRecords0 = static_cast<short int>( hasErased ? (_packedRecords0 | mask) : (_packedRecords0 & ~mask));
                     }
                     
                     
                     
                     inline bool getHasTriggeredEraseForNextIteration() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        short int mask = 1 << (3);
   short int tmp = static_cast<short int>(_packedRecords0 & mask);
   return (tmp != 0);
                     }
                     
                     
                     
                     inline void setHasTriggeredEraseForNextIteration(const bool& hasTriggeredEraseForNextIteration) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        short int mask = 1 << (3);
   _packedRecords0 = static_cast<short int>( hasTriggeredEraseForNextIteration ? (_packedRecords0 | mask) : (_packedRecords0 & ~mask));
                     }
                     
                     
                     
                     inline bool getHasChangedVertexOrCellState() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        short int mask = 1 << (4);
   short int tmp = static_cast<short int>(_packedRecords0 & mask);
   return (tmp != 0);
                     }
                     
                     
                     
                     inline void setHasChangedVertexOrCellState(const bool& hasChangedVertexOrCellState) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        short int mask = 1 << (4);
   _packedRecords0 = static_cast<short int>( hasChangedVertexOrCellState ? (_packedRecords0 | mask) : (_packedRecords0 & ~mask));
                     }
                     
                     
                     
                     inline bool getIsTraversalInverted() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        return _isTraversalInverted;
                     }
                     
                     
                     
                     inline void setIsTraversalInverted(const bool& isTraversalInverted) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                        _isTraversalInverted = isTraversalInverted;
                     }
                     
                     
                     
                  };
                  
               private: 
                  PersistentRecords _persistentRecords;
                  
               public:
                  /**
                   * Generated
                   */
                  StatePacked();
                  
                  /**
                   * Generated
                   */
                  StatePacked(const PersistentRecords& persistentRecords);
                  
                  /**
                   * Generated
                   */
                  StatePacked(const double& updateUMax, const double& updateUH, const double& uMax, const double& uH, const int& timeStep, const double& timeStepSize, const double& time, const double& numberOfStencilUpdates, const int& globalPlotCounter, const tarch::la::Vector<DIMENSIONS,double>& minMeshWidth, const tarch::la::Vector<DIMENSIONS,double>& maxMeshWidth, const double& numberOfInnerVertices, const double& numberOfBoundaryVertices, const double& numberOfOuterVertices, const double& numberOfInnerCells, const double& numberOfOuterCells, const int& maxLevel, const bool& hasRefined, const bool& hasTriggeredRefinementForNextIteration, const bool& hasErased, const bool& hasTriggeredEraseForNextIteration, const bool& hasChangedVertexOrCellState, const bool& isTraversalInverted);
                  
                  /**
                   * Generated
                   */
                  virtual ~StatePacked();
                  
                  
                  inline double getUpdateUMax() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _persistentRecords._updateUMax;
                  }
                  
                  
                  
                  inline void setUpdateUMax(const double& updateUMax) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _persistentRecords._updateUMax = updateUMax;
                  }
                  
                  
                  
                  inline double getUpdateUH() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _persistentRecords._updateUH;
                  }
                  
                  
                  
                  inline void setUpdateUH(const double& updateUH) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _persistentRecords._updateUH = updateUH;
                  }
                  
                  
                  
                  inline double getUMax() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _persistentRecords._uMax;
                  }
                  
                  
                  
                  inline void setUMax(const double& uMax) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _persistentRecords._uMax = uMax;
                  }
                  
                  
                  
                  inline double getUH() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _persistentRecords._uH;
                  }
                  
                  
                  
                  inline void setUH(const double& uH) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _persistentRecords._uH = uH;
                  }
                  
                  
                  
                  inline int getTimeStep() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _persistentRecords._timeStep;
                  }
                  
                  
                  
                  inline void setTimeStep(const int& timeStep) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _persistentRecords._timeStep = timeStep;
                  }
                  
                  
                  
                  inline double getTimeStepSize() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _persistentRecords._timeStepSize;
                  }
                  
                  
                  
                  inline void setTimeStepSize(const double& timeStepSize) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _persistentRecords._timeStepSize = timeStepSize;
                  }
                  
                  
                  
                  inline double getTime() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _persistentRecords._time;
                  }
                  
                  
                  
                  inline void setTime(const double& time) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _persistentRecords._time = time;
                  }
                  
                  
                  
                  inline double getNumberOfStencilUpdates() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _persistentRecords._numberOfStencilUpdates;
                  }
                  
                  
                  
                  inline void setNumberOfStencilUpdates(const double& numberOfStencilUpdates) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _persistentRecords._numberOfStencilUpdates = numberOfStencilUpdates;
                  }
                  
                  
                  
                  inline int getGlobalPlotCounter() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _persistentRecords._globalPlotCounter;
                  }
                  
                  
                  
                  inline void setGlobalPlotCounter(const int& globalPlotCounter) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _persistentRecords._globalPlotCounter = globalPlotCounter;
                  }
                  
                  
                  
                  /**
                   * Generated and optimized
                   * 
                   * If you realise a for loop using exclusively arrays (vectors) and compile 
                   * with -DUseManualAlignment you may add 
                   * \code
                   #pragma vector aligned
                   #pragma simd
                   \endcode to this for loop to enforce your compiler to use SSE/AVX.
                   * 
                   * The alignment is tied to the unpacked records, i.e. for packed class
                   * variants the machine's natural alignment is switched off to recude the  
                   * memory footprint. Do not use any SSE/AVX operations or 
                   * vectorisation on the result for the packed variants, as the data is misaligned. 
                   * If you rely on vectorisation, convert the underlying record 
                   * into the unpacked version first. 
                   * 
                   * @see convert()
                   */
                  inline tarch::la::Vector<DIMENSIONS,double> getMinMeshWidth() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _persistentRecords._minMeshWidth;
                  }
                  
                  
                  
                  /**
                   * Generated and optimized
                   * 
                   * If you realise a for loop using exclusively arrays (vectors) and compile 
                   * with -DUseManualAlignment you may add 
                   * \code
                   #pragma vector aligned
                   #pragma simd
                   \endcode to this for loop to enforce your compiler to use SSE/AVX.
                   * 
                   * The alignment is tied to the unpacked records, i.e. for packed class
                   * variants the machine's natural alignment is switched off to recude the  
                   * memory footprint. Do not use any SSE/AVX operations or 
                   * vectorisation on the result for the packed variants, as the data is misaligned. 
                   * If you rely on vectorisation, convert the underlying record 
                   * into the unpacked version first. 
                   * 
                   * @see convert()
                   */
                  inline void setMinMeshWidth(const tarch::la::Vector<DIMENSIONS,double>& minMeshWidth) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _persistentRecords._minMeshWidth = (minMeshWidth);
                  }
                  
                  
                  
                  inline double getMinMeshWidth(int elementIndex) const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     assertion(elementIndex>=0);
                     assertion(elementIndex<DIMENSIONS);
                     return _persistentRecords._minMeshWidth[elementIndex];
                     
                  }
                  
                  
                  
                  inline void setMinMeshWidth(int elementIndex, const double& minMeshWidth) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     assertion(elementIndex>=0);
                     assertion(elementIndex<DIMENSIONS);
                     _persistentRecords._minMeshWidth[elementIndex]= minMeshWidth;
                     
                  }
                  
                  
                  
                  /**
                   * Generated and optimized
                   * 
                   * If you realise a for loop using exclusively arrays (vectors) and compile 
                   * with -DUseManualAlignment you may add 
                   * \code
                   #pragma vector aligned
                   #pragma simd
                   \endcode to this for loop to enforce your compiler to use SSE/AVX.
                   * 
                   * The alignment is tied to the unpacked records, i.e. for packed class
                   * variants the machine's natural alignment is switched off to recude the  
                   * memory footprint. Do not use any SSE/AVX operations or 
                   * vectorisation on the result for the packed variants, as the data is misaligned. 
                   * If you rely on vectorisation, convert the underlying record 
                   * into the unpacked version first. 
                   * 
                   * @see convert()
                   */
                  inline tarch::la::Vector<DIMENSIONS,double> getMaxMeshWidth() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _persistentRecords._maxMeshWidth;
                  }
                  
                  
                  
                  /**
                   * Generated and optimized
                   * 
                   * If you realise a for loop using exclusively arrays (vectors) and compile 
                   * with -DUseManualAlignment you may add 
                   * \code
                   #pragma vector aligned
                   #pragma simd
                   \endcode to this for loop to enforce your compiler to use SSE/AVX.
                   * 
                   * The alignment is tied to the unpacked records, i.e. for packed class
                   * variants the machine's natural alignment is switched off to recude the  
                   * memory footprint. Do not use any SSE/AVX operations or 
                   * vectorisation on the result for the packed variants, as the data is misaligned. 
                   * If you rely on vectorisation, convert the underlying record 
                   * into the unpacked version first. 
                   * 
                   * @see convert()
                   */
                  inline void setMaxMeshWidth(const tarch::la::Vector<DIMENSIONS,double>& maxMeshWidth) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _persistentRecords._maxMeshWidth = (maxMeshWidth);
                  }
                  
                  
                  
                  inline double getMaxMeshWidth(int elementIndex) const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     assertion(elementIndex>=0);
                     assertion(elementIndex<DIMENSIONS);
                     return _persistentRecords._maxMeshWidth[elementIndex];
                     
                  }
                  
                  
                  
                  inline void setMaxMeshWidth(int elementIndex, const double& maxMeshWidth) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     assertion(elementIndex>=0);
                     assertion(elementIndex<DIMENSIONS);
                     _persistentRecords._maxMeshWidth[elementIndex]= maxMeshWidth;
                     
                  }
                  
                  
                  
                  inline double getNumberOfInnerVertices() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _persistentRecords._numberOfInnerVertices;
                  }
                  
                  
                  
                  inline void setNumberOfInnerVertices(const double& numberOfInnerVertices) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _persistentRecords._numberOfInnerVertices = numberOfInnerVertices;
                  }
                  
                  
                  
                  inline double getNumberOfBoundaryVertices() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _persistentRecords._numberOfBoundaryVertices;
                  }
                  
                  
                  
                  inline void setNumberOfBoundaryVertices(const double& numberOfBoundaryVertices) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _persistentRecords._numberOfBoundaryVertices = numberOfBoundaryVertices;
                  }
                  
                  
                  
                  inline double getNumberOfOuterVertices() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _persistentRecords._numberOfOuterVertices;
                  }
                  
                  
                  
                  inline void setNumberOfOuterVertices(const double& numberOfOuterVertices) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _persistentRecords._numberOfOuterVertices = numberOfOuterVertices;
                  }
                  
                  
                  
                  inline double getNumberOfInnerCells() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _persistentRecords._numberOfInnerCells;
                  }
                  
                  
                  
                  inline void setNumberOfInnerCells(const double& numberOfInnerCells) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _persistentRecords._numberOfInnerCells = numberOfInnerCells;
                  }
                  
                  
                  
                  inline double getNumberOfOuterCells() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _persistentRecords._numberOfOuterCells;
                  }
                  
                  
                  
                  inline void setNumberOfOuterCells(const double& numberOfOuterCells) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _persistentRecords._numberOfOuterCells = numberOfOuterCells;
                  }
                  
                  
                  
                  inline int getMaxLevel() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _persistentRecords._maxLevel;
                  }
                  
                  
                  
                  inline void setMaxLevel(const int& maxLevel) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _persistentRecords._maxLevel = maxLevel;
                  }
                  
                  
                  
                  inline bool getHasRefined() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     short int mask = 1 << (0);
   short int tmp = static_cast<short int>(_persistentRecords._packedRecords0 & mask);
   return (tmp != 0);
                  }
                  
                  
                  
                  inline void setHasRefined(const bool& hasRefined) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     short int mask = 1 << (0);
   _persistentRecords._packedRecords0 = static_cast<short int>( hasRefined ? (_persistentRecords._packedRecords0 | mask) : (_persistentRecords._packedRecords0 & ~mask));
                  }
                  
                  
                  
                  inline bool getHasTriggeredRefinementForNextIteration() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     short int mask = 1 << (1);
   short int tmp = static_cast<short int>(_persistentRecords._packedRecords0 & mask);
   return (tmp != 0);
                  }
                  
                  
                  
                  inline void setHasTriggeredRefinementForNextIteration(const bool& hasTriggeredRefinementForNextIteration) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     short int mask = 1 << (1);
   _persistentRecords._packedRecords0 = static_cast<short int>( hasTriggeredRefinementForNextIteration ? (_persistentRecords._packedRecords0 | mask) : (_persistentRecords._packedRecords0 & ~mask));
                  }
                  
                  
                  
                  inline bool getHasErased() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     short int mask = 1 << (2);
   short int tmp = static_cast<short int>(_persistentRecords._packedRecords0 & mask);
   return (tmp != 0);
                  }
                  
                  
                  
                  inline void setHasErased(const bool& hasErased) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     short int mask = 1 << (2);
   _persistentRecords._packedRecords0 = static_cast<short int>( hasErased ? (_persistentRecords._packedRecords0 | mask) : (_persistentRecords._packedRecords0 & ~mask));
                  }
                  
                  
                  
                  inline bool getHasTriggeredEraseForNextIteration() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     short int mask = 1 << (3);
   short int tmp = static_cast<short int>(_persistentRecords._packedRecords0 & mask);
   return (tmp != 0);
                  }
                  
                  
                  
                  inline void setHasTriggeredEraseForNextIteration(const bool& hasTriggeredEraseForNextIteration) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     short int mask = 1 << (3);
   _persistentRecords._packedRecords0 = static_cast<short int>( hasTriggeredEraseForNextIteration ? (_persistentRecords._packedRecords0 | mask) : (_persistentRecords._packedRecords0 & ~mask));
                  }
                  
                  
                  
                  inline bool getHasChangedVertexOrCellState() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     short int mask = 1 << (4);
   short int tmp = static_cast<short int>(_persistentRecords._packedRecords0 & mask);
   return (tmp != 0);
                  }
                  
                  
                  
                  inline void setHasChangedVertexOrCellState(const bool& hasChangedVertexOrCellState) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     short int mask = 1 << (4);
   _persistentRecords._packedRecords0 = static_cast<short int>( hasChangedVertexOrCellState ? (_persistentRecords._packedRecords0 | mask) : (_persistentRecords._packedRecords0 & ~mask));
                  }
                  
                  
                  
                  inline bool getIsTraversalInverted() const 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     return _persistentRecords._isTraversalInverted;
                  }
                  
                  
                  
                  inline void setIsTraversalInverted(const bool& isTraversalInverted) 
 #ifdef UseManualInlining
 __attribute__((always_inline))
 #endif 
 {
                     _persistentRecords._isTraversalInverted = isTraversalInverted;
                  }
                  
                  
                  /**
                   * Generated
                   */
                  std::string toString() const;
                  
                  /**
                   * Generated
                   */
                  void toString(std::ostream& out) const;
                  
                  
                  PersistentRecords getPersistentRecords() const;
                  /**
                   * Generated
                   */
                  State convert() const;
                  
                  
               #ifdef Parallel
                  protected:
                     static tarch::logging::Log _log;
                     
                     int _senderDestinationRank;
                     
                  public:
                     
                     /**
                      * Global that represents the mpi datatype.
                      * There are two variants: Datatype identifies only those attributes marked with
                      * parallelise. FullDatatype instead identifies the whole record with all fields.
                      */
                     static MPI_Datatype Datatype;
                     static MPI_Datatype FullDatatype;
                     
                     /**
                      * Initializes the data type for the mpi operations. Has to be called
                      * before the very first send or receive operation is called.
                      */
                     static void initDatatype();
                     
                     static void shutdownDatatype();
                     
                     void send(int destination, int tag, bool exchangeOnlyAttributesMarkedWithParallelise);
                     
                     void receive(int source, int tag, bool exchangeOnlyAttributesMarkedWithParallelise);
                     
                     static bool isMessageInQueue(int tag, bool exchangeOnlyAttributesMarkedWithParallelise);
                     
                     int getSenderRank() const;
                     
               #endif
                  
               };
               
               #ifdef PackedRecords
               #pragma pack (pop)
               #endif
               
               
               
            
         #endif
         
         #endif
         
